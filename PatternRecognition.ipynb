{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run input/Format.ipynb\n",
    "import ROOT as root\n",
    "from array import array\n",
    "root.gErrorIgnoreLevel = root.kFatal\n",
    "%jsroot on\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"/Users/mitrankova/Jupyter/PatternRecognition/input/\"\n",
    "#file_names=[\"0version_Box_TPC_Au_Au_ZeroField_1mrad_aligned_10evt_9nSkip_75570-0_resid.root\"]\n",
    "file_names=['Au_Au_seeds_37thevt_66522-0_resid.root']\n",
    "#file_names=['Au_Au_seeds__8evts_7skip_75405-0_resid.root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global mode: use radial triplets everywhere\n",
    "TRIPLET_MODE = \"radial\"\n",
    "\n",
    "def assert_radial():\n",
    "    global TRIPLET_MODE\n",
    "    if TRIPLET_MODE != \"radial\":\n",
    "        print(\"Warning: Forcing TRIPLET_MODE='radial'\")\n",
    "        TRIPLET_MODE = \"radial\"\n",
    "\n",
    "print(\"TRIPLET_MODE:\", TRIPLET_MODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists_read, hists_sim = [], []\n",
    "\n",
    "# Open ROOT files and keep them open so TTrees remain accessible later\n",
    "open_files = []  # keep TFile references alive\n",
    "trees = {\n",
    "    \"cluster\": [],\n",
    "    \"residual\": [],\n",
    "    \"hit\": [],\n",
    "    \"vertex\": []\n",
    "}\n",
    "\n",
    "for iFile in range(len(file_names)):\n",
    "    fpath = file_path + file_names[iFile]\n",
    "    tfile = root.TFile.Open(fpath, \"READ\")\n",
    "    if not tfile or tfile.IsZombie():\n",
    "        print(f\"Failed to open {fpath}\")\n",
    "        trees[\"cluster\"].append(None)\n",
    "        trees[\"residual\"].append(None)\n",
    "        trees[\"hit\"].append(None)\n",
    "        trees[\"vertex\"].append(None)\n",
    "        continue\n",
    "\n",
    "    open_files.append(tfile)\n",
    "\n",
    "    # Retrieve trees if available (names from your file structure)\n",
    "    trees[\"cluster\"].append(tfile.Get(\"clustertree\"))\n",
    "    trees[\"residual\"].append(tfile.Get(\"residualtree\"))\n",
    "    trees[\"hit\"].append(tfile.Get(\"hittree\"))\n",
    "    trees[\"vertex\"].append(tfile.Get(\"vertextree\"))\n",
    "\n",
    "# Handy shorthand to the first file's trees\n",
    "cluster_tree = trees[\"cluster\"][0] if trees[\"cluster\"] else None\n",
    "residual_tree = trees[\"residual\"][0] if trees[\"residual\"] else None\n",
    "hit_tree = trees[\"hit\"][0] if trees[\"hit\"] else None\n",
    "vertex_tree = trees[\"vertex\"][0] if trees[\"vertex\"] else None\n",
    "\n",
    "print(f\"Loaded files: {len(open_files)}\")\n",
    "print(\"hit_tree entries:\", hit_tree.GetEntries() if hit_tree else 0)\n",
    "print(\"cluster_tree entries:\", cluster_tree.GetEntries() if cluster_tree else 0)\n",
    "print(\"residual_tree entries:\", residual_tree.GetEntries() if residual_tree else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check: list a few branches from the trees so they are clearly accessible\n",
    "if hit_tree:\n",
    "    hit_branches = [hit_tree.GetListOfBranches().At(i).GetName() for i in range(min(100, hit_tree.GetListOfBranches().GetEntries()))]\n",
    "    #print(\"hit_tree branches (first 10):\", hit_branches)\n",
    "if cluster_tree:\n",
    "    cluster_branches = [cluster_tree.GetListOfBranches().At(i).GetName() for i in range(min(10, cluster_tree.GetListOfBranches().GetEntries()))]\n",
    "    #print(\"cluster_tree branches (first 10):\", cluster_branches)\n",
    "if residual_tree:\n",
    "    residual_branches = [residual_tree.GetListOfBranches().At(i).GetName() for i in range(min(10, residual_tree.GetListOfBranches().GetEntries()))]\n",
    "    #print(\"residual_tree branches (first 10):\", residual_branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Npads = [94,128,192]\n",
    "ADC_treshold_up = [20, 100, 1000000, 100000]\n",
    "ADC_treshold_down = [0,  20, 60, 200  ]\n",
    "Select_ADC_treshold = 2  # 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {}\n",
    "\n",
    "def get_hist(sector, imod, side):\n",
    "    key = (sector, imod, side)\n",
    "    if key in hists:\n",
    "        return hists[key]\n",
    "\n",
    "    hist = root.TH3F(\n",
    "        f\"hist3d_hard_sec{sector}_m{imod}_s{side}\",\n",
    "        f\"3D ADC sec {sector} mod {imod} side {side}; timebin; pad; layer\",\n",
    "        300, 0,300,\n",
    "        Npads[imod] , Npads[imod] * sector , Npads[imod] * (sector+1),\n",
    "        16, 7 + 16*imod, 7 + 16*(imod + 1)\n",
    "    )\n",
    "    hists[key] = hist\n",
    "    return hist\n",
    "\n",
    "if hit_tree:\n",
    "    n_entries = int(hit_tree.GetEntries())\n",
    "    for entry in range(n_entries):\n",
    "        hit_tree.GetEntry(entry)\n",
    "        sector = int(hit_tree.sector)\n",
    "        layer  = int(hit_tree.layer)\n",
    "        imod   = (layer - 7) // 16\n",
    "        if imod < 0 or imod > 2:\n",
    "            continue\n",
    "\n",
    "        side = int(hit_tree.side)\n",
    "        #print( \"Entry:\", entry, \"Layer:\", layer, \"Imod:\", imod, \"Side:\", side , \"Sector:\", sector)\n",
    "        if side not in (0, 1):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        #if side==0 and sector==0 and imod ==0 :\n",
    "        #    print( hit_tree.adc)\n",
    "        if(hit_tree.adc>ADC_treshold_down[Select_ADC_treshold]):\n",
    "            get_hist(sector, imod, side).Fill( hit_tree.tbin, hit_tree.pad, layer, hit_tree.adc)\n",
    "         #   print(\"Filled!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3d_xyz = root.TH3F(\"hist3d_xyz\", \"3D ADC; x; y;z\", 240, -60, 60, 240, -60, 60, 150,0, 150)\n",
    "if hit_tree:\n",
    "    for entry in range(hit_tree.GetEntries()):\n",
    "        hit_tree.GetEntry(entry)\n",
    "        x_hit = hit_tree.gx\n",
    "        y_hit = hit_tree.gy\n",
    "        z_hit = hit_tree.gz\n",
    "        adc_hit = hit_tree.adc\n",
    "        if (x_hit**2 + y_hit**2)**0.5 > 12:  # only fill if within 100 units\n",
    "            hist3d_xyz.Fill(x_hit, y_hit, z_hit,adc_hit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''c1 = root.TCanvas(\"c1\", \"3D hits\", 1200, 1000)\n",
    "hist3d_xyz.Draw(\"colz\")\n",
    "c1.Draw()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Build Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# collect points per (sector, imod, side)\n",
    "points = defaultdict(list)   # key -> list of (t, pad, layer)\n",
    "payload = defaultdict(list)  # key -> list of (adc, entry)\n",
    "\n",
    "if hit_tree:\n",
    "    n_entries = int(hit_tree.GetEntries())\n",
    "    for entry in range(n_entries):\n",
    "        hit_tree.GetEntry(entry)\n",
    "\n",
    "        sector = int(hit_tree.sector)\n",
    "        layer  = int(hit_tree.layer)\n",
    "        imod   = (layer - 7) // 16\n",
    "        if imod < 0 or imod > 2:\n",
    "            continue\n",
    "\n",
    "        side = int(hit_tree.side)\n",
    "        if side not in (0, 1):\n",
    "            continue\n",
    "\n",
    "        adc = int(hit_tree.adc)\n",
    "        if  (adc < ADC_treshold_down[Select_ADC_treshold]):\n",
    "            continue\n",
    "\n",
    "        tbin = int(hit_tree.tbin)\n",
    "        pad  = int(hit_tree.pad)\n",
    "\n",
    "        key = (sector, imod, side)\n",
    "        points[key].append((tbin, pad, layer))\n",
    "        payload[key].append((adc, entry))\n",
    "        used_global = set()\n",
    "        if sector==0 and imod==0 and side==0:\n",
    "            if layer==7 and tbin<30:\n",
    "            #if tbin>10 and tbin<30 and pad>60 and pad<80 and layer>=7 and layer<8:\n",
    "                print(f\"Entry {entry}: tbin={tbin}, pad={pad}, layer={layer}, adc={adc}\")\n",
    "        \n",
    "\n",
    "# build KD trees\n",
    "kdtree = {}\n",
    "pts_arr = {}\n",
    "for key, pts in points.items():\n",
    "    arr = np.asarray(pts, dtype=np.float32)\n",
    "    pts_arr[key] = arr\n",
    "    kdtree[key] = cKDTree(arr)\n",
    "\n",
    "print(\"Built KD-trees:\", len(kdtree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_query(key, tmin, tmax, pmin, pmax, lmin, lmax):\n",
    "    tree = kdtree[key]\n",
    "    arr  = pts_arr[key]\n",
    "\n",
    "    # cheap preselect using a ball around the box center\n",
    "    center = np.array([(tmin+tmax)/2.0, (pmin+pmax)/2.0, (lmin+lmax)/2.0], dtype=np.float32)\n",
    "    half   = np.array([(tmax-tmin)/2.0, (pmax-pmin)/2.0, (lmax-lmin)/2.0], dtype=np.float32)\n",
    "    radius = float(np.linalg.norm(half))  # ball that covers the whole box\n",
    "\n",
    "    cand = tree.query_ball_point(center, r=radius)\n",
    "\n",
    "    # exact box filter\n",
    "    out = []\n",
    "    for i in cand:\n",
    "        t, p, l = arr[i]\n",
    "        if (tmin <= t <= tmax) and (pmin <= p <= pmax) and (lmin <= l <= lmax):\n",
    "            out.append(i)\n",
    "\n",
    "    return out  # indices into payload[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(key, t, p, l, k=10):\n",
    "    d, idx = kdtree[key].query([t, p, l], k=k)\n",
    "    return d, idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = (0, 0, 0)\n",
    "idxs = box_query(key, tmin=10, tmax=30, pmin=50, pmax=60, lmin=7, lmax=7)\n",
    "\n",
    "print(f\"Box query found {len(idxs)} hits in key {key}:\")\n",
    "\n",
    "for i in idxs:\n",
    "    tbin, pad, layer = pts_arr[key][i]\n",
    "    adc, entry = payload[key][i]\n",
    "    print(f\"  Entry {entry}: tbin={int(tbin)}, pad={int(pad)}, layer={int(layer)}, adc={adc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def build_layer_indices_and_trees(key, pts_arr, payload):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      pts_arr[key]  : Nx3 array (tbin, pad, layer)\n",
    "      payload[key]  : list length N of (adc, entry)\n",
    "    Output:\n",
    "      layers[layer] = dict with:\n",
    "         \"idx\": global indices of hits in this layer\n",
    "         \"tp\" : Mx2 float array of (tbin,pad)\n",
    "         \"adc\": M int array\n",
    "         \"tree\": cKDTree on tp\n",
    "    \"\"\"\n",
    "    arr = pts_arr[key]\n",
    "    adcs = np.array([payload[key][i][0] for i in range(len(payload[key]))], dtype=np.int32)\n",
    "    \n",
    "    by_layer = defaultdict(list)\n",
    "    for i in range(arr.shape[0]):\n",
    "        layer = int(arr[i, 2])\n",
    "        by_layer[layer].append(i)\n",
    "\n",
    "    layers = {}\n",
    "    for layer, idxs in by_layer.items():\n",
    "        idxs = np.asarray(idxs, dtype=np.int32)\n",
    "        tp = arr[idxs][:, :2].astype(np.int32)  # (tbin, pad) as integers\n",
    "        adc = adcs[idxs]\n",
    "        tree = cKDTree(tp.astype(np.float32)) \n",
    "        layers[layer] = {\"idx\": idxs, \"tp\": tp, \"adc\": adc, \"tree\": tree}\n",
    "\n",
    "    return layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Find local ADC maximums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_local_max(layer_data, j):\n",
    "    \"\"\"\n",
    "    8-neighborhood local maximum in (timebin, pad), same layer:\n",
    "    neighbors are |dt|<=1, |dp|<=1 (excluding itself)\n",
    "    \"\"\"\n",
    "    tp   = layer_data[\"tp\"]\n",
    "    adc  = layer_data[\"adc\"]\n",
    "    tree = layer_data[\"tree\"]\n",
    "\n",
    "    a0 = int(adc[j])\n",
    "\n",
    "\n",
    "    t0, p0 = tp[j]\n",
    "    \n",
    "    # radius that fully contains the 3x3 box\n",
    "    r = np.sqrt(2.0)\n",
    "    cand = tree.query_ball_point([t0, p0], r=r)\n",
    "\n",
    "    for k in cand:\n",
    "        if k == j:\n",
    "            continue\n",
    "\n",
    "        t, p = tp[k]\n",
    "        if abs(t - t0) <= 1 and abs(p - p0) <= 1:\n",
    "            if adc[k] >= a0:   # STRICT local max\n",
    "                return False\n",
    "    #print(f\"Found local max at (t={t0}, p={p0}) with adc={a0}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def find_seeds(layers):\n",
    "    \"\"\"\n",
    "    Returns list of seeds as tuples: (layer, j_in_layer)\n",
    "    \"\"\"\n",
    "    seeds = []\n",
    "    for layer, ld in layers.items():\n",
    "        M = ld[\"tp\"].shape[0]\n",
    "        for j in range(M):\n",
    "            if is_local_max(ld, j):\n",
    "                seeds.append((layer, j))\n",
    "    return seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_box_in_layer(layer_data, t0, p0, dt, dp):\n",
    "    tp   = layer_data[\"tp\"]   # int32\n",
    "    tree = layer_data[\"tree\"]\n",
    "\n",
    "    t0 = int(t0); p0 = int(p0)\n",
    "    r = float((dt*dt + dp*dp) ** 0.5)\n",
    "    cand = tree.query_ball_point([float(t0), float(p0)], r=r)\n",
    "\n",
    "    out = []\n",
    "    for j in cand:\n",
    "        t = int(tp[j, 0]); p = int(tp[j, 1])\n",
    "        if abs(t - t0) <= dt and abs(p - p0) <= dp:\n",
    "            out.append(j)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pick_best_candidate(layer_data, cand_js, t0, p0):\n",
    "    tp  = layer_data[\"tp\"]   # int32\n",
    "    adc = layer_data[\"adc\"]\n",
    "\n",
    "    t0 = int(t0); p0 = int(p0)\n",
    "\n",
    "    best = None\n",
    "    best_key = None\n",
    "    for j in cand_js:\n",
    "        t = int(tp[j, 0]); p = int(tp[j, 1])\n",
    "        dist2 = (t - t0)*(t - t0) + (p - p0)*(p - p0)\n",
    "        key = (int(adc[j]), -dist2)\n",
    "        if best is None or key > best_key:\n",
    "            best = j\n",
    "            best_key = key\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_seeds_sorted(layers):\n",
    "    seeds = []\n",
    "    for layer, ld in layers.items():\n",
    "        M = ld[\"tp\"].shape[0]\n",
    "        for j in range(M):\n",
    "            if is_local_max(ld, j):\n",
    "                seeds.append((layer, j, int(ld[\"adc\"][j])))\n",
    "\n",
    "    # highest ADC first\n",
    "    seeds.sort(key=lambda x: x[2], reverse=True)\n",
    "    return seeds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Find horizontal chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def _order_chain_in_layer(layer_data, chain_seed_js):\n",
    "    \"\"\"\n",
    "    Order a set of seed indices (j in this layer) into a 'nice' polyline order.\n",
    "    Uses PCA-like 1D projection when possible; falls back to sorting by (t,p).\n",
    "    \"\"\"\n",
    "    tp = layer_data[\"tp\"]  # int32, shape (M,2)\n",
    "    pts = np.asarray([tp[j] for j in chain_seed_js], dtype=np.float32)  # Nx2\n",
    "\n",
    "    if len(chain_seed_js) <= 2:\n",
    "        # stable ordering\n",
    "        order = np.lexsort((pts[:, 1], pts[:, 0]))  # sort by t then pad\n",
    "        return [chain_seed_js[i] for i in order]\n",
    "\n",
    "    # PCA direction = first right-singular vector of centered coords\n",
    "    c = pts.mean(axis=0, keepdims=True)\n",
    "    X = pts - c\n",
    "    # SVD on 2D: X = U S Vt\n",
    "    _, _, vt = np.linalg.svd(X, full_matrices=False)\n",
    "    direction = vt[0]  # 2-vector\n",
    "\n",
    "    s = X @ direction  # projection coordinate\n",
    "    order = np.argsort(s)\n",
    "    return [chain_seed_js[i] for i in order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_avg_dp_dt_between_maxima(chain, layers, seed_set):\n",
    "    \"\"\"\n",
    "    Returns (avg_dp, avg_dt, n_maxima) using absolute dp/dt\n",
    "    between consecutive maxima in the given chain order.\n",
    "    \"\"\"\n",
    "    maxima = [node for node in chain if node in seed_set]\n",
    "    if len(maxima) < 2:\n",
    "        return None, None, len(maxima)\n",
    "\n",
    "    dp_diffs = []\n",
    "    dt_diffs = []\n",
    "    for (ly1, j1), (ly2, j2) in zip(maxima, maxima[1:]):\n",
    "        t1, p1 = layers[int(ly1)][\"tp\"][int(j1)]\n",
    "        t2, p2 = layers[int(ly2)][\"tp\"][int(j2)]\n",
    "        dp_diffs.append(abs(int(p2) - int(p1)))\n",
    "        dt_diffs.append(abs(int(t2) - int(t1)))\n",
    "\n",
    "    return float(np.mean(dp_diffs)), float(np.mean(dt_diffs)), len(maxima)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def build_horizontal_cluster_allhits_from_seed(layers, seed_layer, seed_j, used_global,\n",
    "                                               dt=2, dp=1):\n",
    "    \"\"\"\n",
    "    Flood-fill in ONE layer from a seed, collecting ALL connected hits (same layer),\n",
    "    using |dt|<=dt, |dp|<=dp.\n",
    "\n",
    "    Marks hits as used during the fill, but returns the list of global indices it claimed\n",
    "    so caller can UNDO if the cluster is rejected by quality cuts.\n",
    "    \"\"\"\n",
    "    layer = int(seed_layer)\n",
    "    ld = layers.get(layer)\n",
    "    if ld is None:\n",
    "        return [], []\n",
    "\n",
    "    seed_j = int(seed_j)\n",
    "    gi_seed = int(ld[\"idx\"][seed_j])\n",
    "    if gi_seed in used_global:\n",
    "        return [], []\n",
    "\n",
    "    q = deque([seed_j])\n",
    "    visited_local = set([seed_j])\n",
    "\n",
    "    chain_js = []\n",
    "    consumed_gis = []\n",
    "\n",
    "    while q:\n",
    "        j = int(q.popleft())\n",
    "        gi = int(ld[\"idx\"][j])\n",
    "\n",
    "        # if already used by some earlier accepted chain, don't take it\n",
    "        if gi in used_global:\n",
    "            continue\n",
    "\n",
    "        # claim it\n",
    "        used_global.add(gi)\n",
    "        consumed_gis.append(gi)\n",
    "        chain_js.append(j)\n",
    "\n",
    "        t0 = int(ld[\"tp\"][j, 0])\n",
    "        p0 = int(ld[\"tp\"][j, 1])\n",
    "\n",
    "        neigh = query_box_in_layer(ld, t0, p0, dt=dt, dp=dp)\n",
    "        for nj in neigh:\n",
    "            nj = int(nj)\n",
    "            if nj in visited_local:\n",
    "                continue\n",
    "            visited_local.add(nj)\n",
    "            q.append(nj)\n",
    "\n",
    "    chain = [(layer, j) for j in chain_js]\n",
    "    return chain, consumed_gis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_horizontal_chains_allhits(layers, seeds_sorted, used_global,\n",
    "                                   dt=2, dp=1,\n",
    "                                   min_hits=3,\n",
    "                                   min_pad_span=5,      # <-- require (pmax - pmin) > 5\n",
    "                                   order_for_drawing=True):\n",
    "    \"\"\"\n",
    "    seeds_sorted: list of (layer, j, adc) sorted by adc desc\n",
    "    Builds horizontal clusters; accepts only if:\n",
    "      - len(cluster) >= min_hits\n",
    "      - pad span (pmax - pmin) > min_pad_span\n",
    "    If rejected: UNDO used_global claims for that cluster.\n",
    "    \"\"\"\n",
    "    horizontal_chains = []\n",
    "\n",
    "    for (layer, j, adc) in seeds_sorted:\n",
    "        chain, consumed_gis = build_horizontal_cluster_allhits_from_seed(\n",
    "            layers, layer, j, used_global, dt=dt, dp=dp\n",
    "        )\n",
    "        if not chain:\n",
    "            continue\n",
    "\n",
    "        ly = int(chain[0][0])\n",
    "        ld = layers[ly]\n",
    "        js = [jj for (_, jj) in chain]\n",
    "\n",
    "        # compute pad span\n",
    "        pads = [int(ld[\"tp\"][jj, 1]) for jj in js]\n",
    "        pad_span = (max(pads) - min(pads)) if pads else 0\n",
    "\n",
    "        # acceptance cuts\n",
    "        if len(js) < min_hits or pad_span <= min_pad_span:\n",
    "            # rollback: free hits for vertical iteration / other chains\n",
    "            for gi in consumed_gis:\n",
    "                used_global.discard(int(gi))\n",
    "            continue\n",
    "\n",
    "        if order_for_drawing:\n",
    "            js_ord = _order_chain_in_layer(ld, js)\n",
    "            chain = [(ly, int(jj)) for jj in js_ord]\n",
    "\n",
    "        horizontal_chains.append(chain)\n",
    "\n",
    "    return horizontal_chains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Build Vertical chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _wls_line(x, y, w):\n",
    "    \"\"\"\n",
    "    Weighted least squares for y = a + b*x\n",
    "    Returns (a, b).\n",
    "    \"\"\"\n",
    "    sw = sx = sy = sxx = sxy = 0.0\n",
    "    for xi, yi, wi in zip(x, y, w):\n",
    "        wi = float(wi)\n",
    "        if wi <= 0:\n",
    "            continue\n",
    "        sw  += wi\n",
    "        sx  += wi * xi\n",
    "        sy  += wi * yi\n",
    "        sxx += wi * xi * xi\n",
    "        sxy += wi * xi * yi\n",
    "\n",
    "    if sw <= 0:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    denom = (sw * sxx - sx * sx)\n",
    "    if denom == 0:\n",
    "        a = sy / sw\n",
    "        b = 0.0\n",
    "        return a, b\n",
    "\n",
    "    b = (sw * sxy - sx * sy) / denom\n",
    "    a = (sy - b * sx) / sw\n",
    "    return a, b\n",
    "\n",
    "\n",
    "def _fit_from_pts(pts):\n",
    "    \"\"\"pts = [(L,t,p,w), ...] -> (at,bt, ap,bp)\"\"\"\n",
    "    xs = [float(L) for (L, t, p, w) in pts]\n",
    "    ts = [float(t) for (L, t, p, w) in pts]\n",
    "    ps = [float(p) for (L, t, p, w) in pts]\n",
    "    ws = [float(w) for (L, t, p, w) in pts]\n",
    "    at, bt = _wls_line(xs, ts, ws)\n",
    "    ap, bp = _wls_line(xs, ps, ws)\n",
    "    return at, bt, ap, bp\n",
    "\n",
    "\n",
    "def _build_anchor_index(layers, chains_main_list, chain_id_list=None):\n",
    "\n",
    "    if chain_id_list is None:\n",
    "        chain_id_list = list(range(len(chains_main_list)))\n",
    "\n",
    "    anchors_by_layer = {}\n",
    "    for cid in chain_id_list:\n",
    "        chain = chains_main_list[cid]\n",
    "        for L, j in chain:\n",
    "            ld = layers.get(L)\n",
    "            if ld is None:\n",
    "                continue\n",
    "            t = int(ld[\"tp\"][j, 0])\n",
    "            p = int(ld[\"tp\"][j, 1])\n",
    "            gi = int(ld[\"idx\"][j])\n",
    "            anchors_by_layer.setdefault(int(L), []).append(\n",
    "                {\"t\": t, \"p\": p, \"gi\": gi, \"chain_id\": cid, \"j\": int(j)}\n",
    "            )\n",
    "    return anchors_by_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_chain_from_seed_unique_dir(\n",
    "    layers, seed_layer, seed_j, used_global, seed_set,\n",
    "    dt_win0=3, dp_win0=2,\n",
    "    layer_step=1,\n",
    "    dt_gate=1, dp_gate=1,\n",
    "    allow_skip_one_layer=True,\n",
    "    anchors_by_layer=None,\n",
    "    allow_merge_to_anchors=True,\n",
    "    allow_merge_same_layer=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Directional chaining that:\n",
    "    - Uses ALL hits in window for fitting\n",
    "    - Stores seed hits in chain_main\n",
    "    - Stores non-seed hits in chain_support\n",
    "    \n",
    "    Returns: chain_main, chain_support, fit_history, merge_chain_id\n",
    "    \"\"\"\n",
    "    chain_main = []\n",
    "    chain_support = []\n",
    "    fit_history = []\n",
    "    merge_chain_id = None\n",
    "\n",
    "    cur_layer = int(seed_layer)\n",
    "    cur_j = int(seed_j)\n",
    "    \n",
    "    ld0 = layers.get(cur_layer)\n",
    "    if ld0 is None:\n",
    "        return chain_main, chain_support, fit_history, merge_chain_id\n",
    "\n",
    "    gi0 = int(ld0[\"idx\"][cur_j])\n",
    "    if gi0 in used_global:\n",
    "        return chain_main, chain_support, fit_history, merge_chain_id\n",
    "\n",
    "    # Seed hit\n",
    "    t0 = int(ld0[\"tp\"][cur_j, 0])\n",
    "    p0 = int(ld0[\"tp\"][cur_j, 1])\n",
    "    w0 = float(ld0[\"adc\"][cur_j])\n",
    "    ##print(\"--------------------------------------------------\")\n",
    "    #print(\"Starting chain from seed at layer\", cur_layer, \"j\", cur_j, \"t=\", t0, \"p=\", p0, \"w=\", w0)\n",
    "    chain_main.append((cur_layer, cur_j))\n",
    "    used_global.add(gi0)\n",
    "    \n",
    "    # For fitting: store (L, t, p, w)\n",
    "    pts = [(cur_layer, t0, p0, w0)]\n",
    "    \n",
    "    at = bt = ap = bp = None\n",
    "\n",
    "    def _collect_hits_in_box(layer_num, t_center, p_center, dt, dp):\n",
    "        \"\"\"Returns (seed_js, support_js) both lists of j-indices\"\"\"\n",
    "        ld = layers.get(layer_num)\n",
    "        if ld is None:\n",
    "            return [], []\n",
    "        \n",
    "        js = query_box_in_layer(ld, int(t_center), int(p_center), int(dt), int(dp))\n",
    "        seed_js = []\n",
    "        support_js = []\n",
    "        #print(\"Layer\", layer_num, \"found\", len(js), \"hits in box centered at t=\", t_center, \"p=\", p_center)\n",
    "        for j in js:\n",
    "            gi = int(ld[\"idx\"][j])\n",
    "            if gi in used_global:\n",
    "                continue\n",
    "            \n",
    "            is_seed = (int(layer_num), int(j)) in seed_set\n",
    "            if is_seed:\n",
    "                seed_js.append(int(j))\n",
    "                ##print(\"  Seed hit:\", layer_num, j)\n",
    "            else:\n",
    "                support_js.append(int(j))\n",
    "                #print(\"  Support hit:\", layer_num, j)\n",
    "        \n",
    "        return seed_js, support_js\n",
    "\n",
    "    def _find_anchor_merge(layer_num, t_center, p_center, dt, dp):\n",
    "        \"\"\"Look for pass-1 anchor hits for merging\"\"\"\n",
    "        if not allow_merge_to_anchors or anchors_by_layer is None:\n",
    "            return None\n",
    "        \n",
    "        lst = anchors_by_layer.get(int(layer_num), [])\n",
    "        if not lst:\n",
    "            return None\n",
    "\n",
    "        # Count anchor hits in window by chain_id\n",
    "        counts = {}\n",
    "        for a in lst:\n",
    "            #print(\"  Anchor hit at layer\", layer_num, \"t=\", a[\"t\"], \"p=\", a[\"p\"], \"chain_id=\", a[\"chain_id\"])\n",
    "            if abs(a[\"t\"] - t_center) <= dt and abs(a[\"p\"] - p_center) <= dp:\n",
    "                counts[a[\"chain_id\"]] = counts.get(a[\"chain_id\"], 0) + 1\n",
    "\n",
    "        if not counts:\n",
    "            return None\n",
    "\n",
    "        # Return chain with max count\n",
    "        return max(counts.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    def _try_anchor_merge(layers_to_try, t_center, p_center, dt, dp):\n",
    "        \"\"\"Try anchor-merge in the given layer order; returns chain_id or None.\"\"\"\n",
    "        for L in layers_to_try:\n",
    "            cid = _find_anchor_merge(int(L), t_center, p_center, dt, dp)\n",
    "            if cid is not None:\n",
    "                return cid\n",
    "        return None\n",
    "\n",
    "\n",
    "    def _accept_group(layer_num, seed_js, support_js):\n",
    "        \"\"\"Add hits to chains and fitting points, mark as used\"\"\"\n",
    "        ld = layers[layer_num]\n",
    "        \n",
    "        # Process seed hits\n",
    "        for j in seed_js:\n",
    "            gi = int(ld[\"idx\"][j])\n",
    "            if gi in used_global:\n",
    "                continue\n",
    "            t = int(ld[\"tp\"][j, 0])\n",
    "            p = int(ld[\"tp\"][j, 1])\n",
    "            w = float(ld[\"adc\"][j])\n",
    "            chain_main.append((layer_num, j))\n",
    "            used_global.add(gi)\n",
    "            pts.append((layer_num, t, p, w))\n",
    "            #print(\"Accepted seed hit:\", layer_num, j, \"t=\", t, \"p=\", p, \"w=\", w)\n",
    "        \n",
    "        # Process support hits (for fitting only)\n",
    "        for j in support_js:\n",
    "            gi = int(ld[\"idx\"][j])\n",
    "            if gi in used_global:\n",
    "                continue\n",
    "            t = int(ld[\"tp\"][j, 0])\n",
    "            p = int(ld[\"tp\"][j, 1])\n",
    "            w = float(ld[\"adc\"][j])\n",
    "            chain_support.append((layer_num, j))\n",
    "            used_global.add(gi)\n",
    "            pts.append((layer_num, t, p, w))\n",
    "            #print(\"Accepted support hit:\", layer_num, j, \"t=\", t, \"p=\", p, \"w=\", w)\n",
    "        \n",
    "\n",
    "    def _refit_and_store():\n",
    "        nonlocal at, bt, ap, bp\n",
    "        at, bt, ap, bp = _fit_from_pts(pts)\n",
    "        fit_history.append({\n",
    "            \"n_hits\": len(pts),\n",
    "            \"n_seeds\": len(chain_main),\n",
    "            \"n_support\": len(chain_support),\n",
    "            \"t_fit\": {\"a\": at, \"b\": bt},\n",
    "            \"p_fit\": {\"a\": ap, \"b\": bp},\n",
    "        })\n",
    "        #print(f\"Refit: n_hits={len(pts)}, n_seeds={len(chain_main)}, n_support={len(chain_support)}, at={at:.2f}, bt={bt:.4f}, ap={ap:.2f}, bp={bp:.4f}\")\n",
    "\n",
    "    # ---- Step 1: First group in next layer ----\n",
    "    next_layer = cur_layer + layer_step\n",
    "    seed_js, support_js = _collect_hits_in_box(next_layer, t0, p0, dt_win0, dp_win0)\n",
    "\n",
    "    # Try skipping one layer if nothing found\n",
    "    if not seed_js and not support_js and allow_skip_one_layer:\n",
    "        #print(\"No hits found in next layer, trying skip one layer\")\n",
    "        next2 = next_layer + layer_step\n",
    "        seed_js, support_js = _collect_hits_in_box(next2, t0, p0, dt_win0, dp_win0)\n",
    "        if seed_js or support_js:\n",
    "            next_layer = next2\n",
    "\n",
    "    # Check for merge if no hits found\n",
    "    '''if not seed_js and not support_js:\n",
    "        if allow_merge_to_anchors:\n",
    "            cid = _find_anchor_merge(next_layer, t0, p0, dt_win0, dp_win0)\n",
    "            if cid is None and allow_skip_one_layer:\n",
    "                cid = _find_anchor_merge(next_layer + layer_step, t0, p0, dt_win0, dp_win0)\n",
    "            if cid is not None:\n",
    "                merge_chain_id = cid\n",
    "        return chain_main, chain_support, fit_history, merge_chain_id'''\n",
    "    # Check for merge if no hits found\n",
    "    if not seed_js and not support_js:\n",
    "        if allow_merge_to_anchors:\n",
    "            layers_to_try = [next_layer]\n",
    "            if allow_skip_one_layer:\n",
    "                layers_to_try.append(next_layer + layer_step)\n",
    "            if allow_merge_same_layer:\n",
    "                layers_to_try.insert(0, cur_layer)   # <--- SAME LAYER FIRST\n",
    "\n",
    "            cid = _try_anchor_merge(layers_to_try, t0, p0, dt_win0, dp_win0)\n",
    "            if cid is not None:\n",
    "                merge_chain_id = cid\n",
    "        return chain_main, chain_support, fit_history, merge_chain_id\n",
    "\n",
    "\n",
    "    _accept_group(next_layer, seed_js, support_js)\n",
    "    _refit_and_store()\n",
    "    cur_layer = next_layer\n",
    "\n",
    "    # ---- Subsequent steps: Fit prediction with gating ----\n",
    "    while True:\n",
    "        target = cur_layer + layer_step\n",
    "        if target not in layers:\n",
    "            break\n",
    "\n",
    "        t_pred = at + bt * float(target)\n",
    "        p_pred = ap + bp * float(target)\n",
    "        #print(f\"Predicting for layer {target}: t={t_pred:.2f}, p={p_pred:.2f}\")\n",
    "        seed_js, support_js = _collect_hits_in_box(target, t_pred, p_pred, dt_gate, dp_gate)\n",
    "\n",
    "        # Try skip if empty\n",
    "        if not seed_js and not support_js and allow_skip_one_layer:\n",
    "            target2 = target + layer_step\n",
    "            if target2 in layers:\n",
    "                t_pred2 = at + bt * float(target2)\n",
    "                p_pred2 = ap + bp * float(target2)\n",
    "                seed_js, support_js = _collect_hits_in_box(target2, t_pred2, p_pred2, dt_gate, dp_gate)\n",
    "                if seed_js or support_js:\n",
    "                    target = target2\n",
    "                    t_pred = t_pred2\n",
    "                    p_pred = p_pred2\n",
    "\n",
    "        # Check for merge\n",
    "        if not seed_js and not support_js:\n",
    "            #print(\"Look for merge at layer\", target)\n",
    "            if allow_merge_to_anchors:\n",
    "                cid = _find_anchor_merge(target, t_pred, p_pred, dt_gate, dp_gate)\n",
    "                if cid is None and allow_skip_one_layer:\n",
    "                    cid = _find_anchor_merge(target + layer_step, t_pred, p_pred, dt_gate, dp_gate)\n",
    "                if cid is not None:\n",
    "                    merge_chain_id = cid\n",
    "            break\n",
    "\n",
    "        _accept_group(target, seed_js, support_js)\n",
    "        _refit_and_store()\n",
    "        cur_layer = target\n",
    "\n",
    "    return chain_main, chain_support, fit_history, merge_chain_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### TOP TO BOTTOM ###############\n",
    "def two_pass_chaining(\n",
    "    layers, seeds_sorted, seed_set,\n",
    "    dt_win0=3, dp_win0=2, dt_gate=1, dp_gate=1,\n",
    "    allow_skip_one_layer=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Two-pass chaining with corrected logic:\n",
    "    PASS 1: TOP → BOTTOM (creates anchor chains)\n",
    "    PASS 2: BOTTOM → TOP (merges into anchors)\n",
    "    Returns: list of (chain_main, chain_support) tuples\n",
    "    \"\"\"\n",
    "    used = set()\n",
    "    \n",
    "    # ---- PASS 1: TOP → BOTTOM (no merging, creates anchors) ----\n",
    "    print(\"=\"*60)\n",
    "    print(\"PASS 1: TOP → BOTTOM (creating anchor chains)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    seeds_topdown = sorted(seeds_sorted, key=lambda x: -int(x[0]))\n",
    "    chains_pass1 = []\n",
    "    \n",
    "    for ly, j, adc in seeds_topdown:\n",
    "        chain_m, chain_s, hist, merge_id = build_chain_from_seed_unique_dir(\n",
    "            layers, int(ly), int(j), used, seed_set,\n",
    "            dt_win0=dt_win0, dp_win0=dp_win0,\n",
    "            layer_step=-1,  # Going DOWN\n",
    "            dt_gate=dt_gate, dp_gate=dp_gate,\n",
    "            allow_skip_one_layer=allow_skip_one_layer,\n",
    "            anchors_by_layer=None,  # No anchors in pass 1\n",
    "            allow_merge_to_anchors=False\n",
    "        )\n",
    "        if len(chain_m) >= 2:\n",
    "            chains_pass1.append((chain_m, chain_s))\n",
    "            #print(f\"Pass 1 chain {len(chains_pass1)-1}: {len(chain_m)} main + {len(chain_s)} support hits\")\n",
    "    \n",
    "    print(f\"\\nPass 1 complete: {len(chains_pass1)} chains created\")\n",
    "    \n",
    "    # Build anchor index from pass-1 main chains\n",
    "    anchors_by_layer = _build_anchor_index(layers, [c[0] for c in chains_pass1])\n",
    "    \n",
    "    # Debug: print anchor counts\n",
    "    total_anchors = sum(len(v) for v in anchors_by_layer.values())\n",
    "    #print(f\"Built anchor index: {total_anchors} anchors across {len(anchors_by_layer)} layers\")\n",
    "    #for layer_num in sorted(anchors_by_layer.keys()):\n",
    "        #print(f\"  Layer {layer_num}: {len(anchors_by_layer[layer_num])} anchors\")\n",
    "    \n",
    "    # ---- PASS 2: BOTTOM → TOP (with merging) ----\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PASS 2: BOTTOM → TOP (merging into anchors)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    seeds_bottomup = sorted(seeds_sorted, key=lambda x: int(x[0]))\n",
    "    merged_chain_ids = set()\n",
    "    chains_pass2 = []\n",
    "    \n",
    "    for ly, j, adc in seeds_bottomup:\n",
    "        chain_m, chain_s, hist, merge_id = build_chain_from_seed_unique_dir(\n",
    "            layers, int(ly), int(j), used, seed_set,\n",
    "            dt_win0=dt_win0, dp_win0=dp_win0,\n",
    "            layer_step=+1,  # Going UP\n",
    "            dt_gate=dt_gate, dp_gate=dp_gate,\n",
    "            allow_skip_one_layer=allow_skip_one_layer,\n",
    "            anchors_by_layer=anchors_by_layer,\n",
    "            allow_merge_to_anchors=True,\n",
    "            allow_merge_same_layer=True, \n",
    "        )\n",
    "        \n",
    "        if len(chain_m) < 2:\n",
    "            continue\n",
    "        \n",
    "        if merge_id is not None:\n",
    "            #print(f\"MERGE DETECTED: Pass 2 chain merging into Pass 1 chain {merge_id}\")\n",
    "            \n",
    "            if merge_id not in merged_chain_ids:\n",
    "                # First time merging into this anchor chain\n",
    "                merged_chain_ids.add(merge_id)\n",
    "                \n",
    "                # Combine: pass2 chain + pass1 anchor chain\n",
    "                merged_main = list(chain_m) + list(chains_pass1[merge_id][0])\n",
    "                merged_support = list(chain_s) + list(chains_pass1[merge_id][1])\n",
    "                \n",
    "                chains_pass2.append((merged_main, merged_support))\n",
    "                #print(f\"  Created merged chain: {len(merged_main)} main + {len(merged_support)} support\")\n",
    "            else:\n",
    "                # Already merged into this anchor - just add as standalone\n",
    "                #print(f\"  Anchor {merge_id} already merged, adding as standalone chain\")\n",
    "                chains_pass2.append((chain_m, chain_s))\n",
    "        else:\n",
    "            # No merge, add as standalone\n",
    "            chains_pass2.append((chain_m, chain_s))\n",
    "            #print(f\"Pass 2 standalone chain: {len(chain_m)} main + {len(chain_s)} support hits\")\n",
    "    \n",
    "    print(f\"\\nPass 2 complete: {len(chains_pass2)} chains created ({len(merged_chain_ids)} merged)\")\n",
    "    \n",
    "    # ---- COMBINE RESULTS ----\n",
    "    # Add unmerged pass-1 chains + all pass-2 chains\n",
    "    final_chains = []\n",
    "    \n",
    "    for i, (chain_m, chain_s) in enumerate(chains_pass1):\n",
    "        if i not in merged_chain_ids:\n",
    "            final_chains.append((chain_m, chain_s))\n",
    "    \n",
    "    final_chains.extend(chains_pass2)\n",
    "    \n",
    "    print(f\"\\nFinal result: {len(final_chains)} total chains\")\n",
    "    print(f\"  {len(chains_pass1) - len(merged_chain_ids)} unmerged from pass 1\")\n",
    "    print(f\"  {len(chains_pass2)} from pass 2 (including {len(merged_chain_ids)} merged)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return final_chains\n",
    "\n",
    "\n",
    "def _build_anchor_index(layers, chain_mains):\n",
    "    \"\"\"\n",
    "    Build index of anchor hits by layer.\n",
    "    Returns: {layer_num: [{\"t\": t, \"p\": p, \"chain_id\": i}, ...]}\n",
    "    \"\"\"\n",
    "    anchors = {}\n",
    "    \n",
    "    for chain_id, chain_main in enumerate(chain_mains):\n",
    "        for layer_num, j in chain_main:\n",
    "            ld = layers.get(int(layer_num))\n",
    "            if ld is None:\n",
    "                continue\n",
    "            \n",
    "            t = int(ld[\"tp\"][j, 0])\n",
    "            p = int(ld[\"tp\"][j, 1])\n",
    "            \n",
    "            if layer_num not in anchors:\n",
    "                anchors[layer_num] = []\n",
    "            \n",
    "            anchors[layer_num].append({\n",
    "                \"t\": t,\n",
    "                \"p\": p,\n",
    "                \"chain_id\": chain_id\n",
    "            })\n",
    "    \n",
    "    return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_chain(key, chain_main, chain_support, layers, pts_arr, payload, max_lines=200):\n",
    "    print(f\"\\n=== CHAIN key={key} main_hits={len(chain_main)} support_hits={len(chain_support)} ===\")\n",
    "\n",
    "    def print_hit(layer, j):\n",
    "        gi = int(layers[layer][\"idx\"][j])  # global index\n",
    "        tbin, pad, layer0 = pts_arr[key][gi]\n",
    "        adc, entry = payload[key][gi]\n",
    "        print(f\"  L={int(layer0):2d}  t={int(tbin):3d}  pad={int(pad):4d}  adc={int(adc):5d}  entry={entry}\")\n",
    "\n",
    "    print(\"Main hits:\")\n",
    "    for (layer, j) in chain_main[:max_lines]:\n",
    "        print_hit(layer, j)\n",
    "\n",
    "    # If you want to see supports too:\n",
    "    print(\"Support hits:\")\n",
    "    for (layer, j) in chain_support[:max_lines]:\n",
    "        print_hit(layer, j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "key = (0, 0, 0)\n",
    "layers = build_layer_indices_and_trees(key, pts_arr, payload)       \n",
    "seeds_sorted = find_seeds_sorted(layers)\n",
    "print(f\"\\nFound {len(seeds_sorted)} seeds in key {key}:\")\n",
    "for i, (layer, j,adc) in enumerate(seeds_sorted):\n",
    "\n",
    "    #print(f\"\\nSeed {layer}: Layer={j[0]}  j_in_layer={j[1]}  adc={j[2]}\")\n",
    "    gi = int(layers[layer][\"idx\"][j])  # global index in pts_arr[key]\n",
    "    tbin, pad, layer0 = pts_arr[key][gi]\n",
    "    if layer==7:\n",
    "        print(f\"Seed {i:3d}: L={int(layer0):2d}  t={int(tbin):3d}  pad={int(pad):4d}  adc={int(layers[layer]['adc'][j]):5d}  entry={payload[key][gi][1]}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''key = (0, 0, 0)\n",
    "layers = build_layer_indices_and_trees(key, pts_arr, payload)\n",
    "\n",
    "seeds_sorted = find_seeds_sorted(layers)   # (layer, j, adc)\n",
    "print(\"Total number of ADC maximums:\", len(seeds_sorted))\n",
    "\n",
    "used_global = set()\n",
    "seed_set = set((int(ly), int(j)) for (ly, j, adc) in seeds_sorted)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# ---- 1st iteration: horizontal chains (same layer) INCLUDING ALL hits ----\n",
    "horizontal_chains = find_horizontal_chains_allhits(\n",
    "    layers, seeds_sorted, used_global,\n",
    "    dt=2, dp=1,\n",
    "    min_hits=3,\n",
    "    min_pad_span=5,\n",
    "    order_for_drawing=True\n",
    ")\n",
    "\n",
    "horizontal_chain_avg_dpdts = []\n",
    "for chain in horizontal_chains:\n",
    "    avg_dp, avg_dt, n_max = chain_avg_dp_dt_between_maxima(chain, layers, seed_set)\n",
    "    horizontal_chain_avg_dpdts.append((avg_dp, avg_dt, n_max))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# NEW: vertical chaining = TWO PASS (top->bottom) + (bottom->top w/ merge)\n",
    "# IMPORTANT: reuse the SAME used_global that horizontal pass already filled.\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Use ALL seeds; two_pass_chaining will skip those already used_global.\n",
    "seed_set = {(ly, j) for ly, j, adc in seeds_sorted}\n",
    "\n",
    "final_vertical_chains = two_pass_chaining(\n",
    "    layers, seeds_sorted, seed_set,  # Add seed_set\n",
    "    dt_win0=3, dp_win0=2,\n",
    "    dt_gate=1, dp_gate=1,\n",
    "    allow_skip_one_layer=True\n",
    ")\n",
    "\n",
    "for chain_main, chain_support in final_vertical_chains[3:4]:\n",
    "    avg_dp, avg_dt, n_max = chain_avg_dp_dt_between_maxima(\n",
    "        chain_main, layers, seed_set\n",
    "    )\n",
    "    dump_chain(key, chain_main, chain_support, layers, pts_arr, payload)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def sagitta_fit_3d(chain, key, layers, pts_arr, payload):\n",
    "    \"\"\"\n",
    "    Perform weighted parabolic (sagitta) fit on a chain of hits.\n",
    "    \n",
    "    Returns:\n",
    "        fit_params: dict with fit parameters and quality metrics\n",
    "        fit_line: TPolyLine3D for drawing the fit\n",
    "    \"\"\"\n",
    "    if len(chain) < 3:\n",
    "        return None, None\n",
    "    \n",
    "    # Extract hit coordinates and ADC weights\n",
    "    points = []\n",
    "    weights = []\n",
    "    \n",
    "    for (layer, j) in chain:\n",
    "        gi = int(layers[layer][\"idx\"][j])\n",
    "        tbin, pad, layer_val = pts_arr[key][gi]\n",
    "        adc, entry = payload[key][gi]\n",
    "        \n",
    "        points.append([float(tbin), float(pad), float(layer_val)])\n",
    "        weights.append(float(adc))\n",
    "    \n",
    "    points = np.array(points)\n",
    "    weights = np.array(weights)\n",
    "    \n",
    "    # Fit pad vs layer (parabola in pad-layer plane)\n",
    "    # pad = a*layer^2 + b*layer + c\n",
    "    # tbin = d*layer + e\n",
    "    \n",
    "    layers_arr = points[:, 2]\n",
    "    pads_arr = points[:, 1]\n",
    "    tbins_arr = points[:, 0]\n",
    "    \n",
    "    # Weighted parabolic fit for pad vs layer\n",
    "    try:\n",
    "        # Fit pad = a*layer^2 + b*layer + c\n",
    "        def parabola(x, a, b, c):\n",
    "            return a * x**2 + b * x + c\n",
    "        \n",
    "        popt_pad, pcov_pad = curve_fit(\n",
    "            parabola, layers_arr, pads_arr, \n",
    "            sigma=1.0/np.sqrt(weights),\n",
    "            absolute_sigma=False\n",
    "        )\n",
    "        \n",
    "        # Linear fit for tbin vs layer\n",
    "        def linear(x, d, e):\n",
    "            return d * x + e\n",
    "        \n",
    "        popt_tbin, pcov_tbin = curve_fit(\n",
    "            linear, layers_arr, tbins_arr,\n",
    "            sigma=1.0/np.sqrt(weights),\n",
    "            absolute_sigma=False\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Fit failed: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Calculate residuals and chi-squared\n",
    "    pad_fit = parabola(layers_arr, *popt_pad)\n",
    "    tbin_fit = linear(layers_arr, *popt_tbin)\n",
    "    \n",
    "    pad_residuals = pads_arr - pad_fit\n",
    "    tbin_residuals = tbins_arr - tbin_fit\n",
    "    \n",
    "    # Weighted chi-squared\n",
    "    chi2_pad = np.sum(weights * pad_residuals**2) / np.sum(weights)\n",
    "    chi2_tbin = np.sum(weights * tbin_residuals**2) / np.sum(weights)\n",
    "    \n",
    "    # Calculate sagitta (maximum deviation from straight line)\n",
    "    layer_min, layer_max = layers_arr.min(), layers_arr.max()\n",
    "    if layer_max == layer_min or layer_max - layer_min <= 1:\n",
    "        return None, None\n",
    "    layer_mid = (layer_min + layer_max) / 2.0\n",
    "    \n",
    "    # Straight line connecting endpoints in pad-layer plane\n",
    "    pad_start = parabola(layer_min, *popt_pad)\n",
    "    pad_end = parabola(layer_max, *popt_pad)\n",
    "    pad_straight = pad_start + (pad_end - pad_start) * (layer_mid - layer_min) / (layer_max - layer_min)\n",
    "    pad_parabola = parabola(layer_mid, *popt_pad)\n",
    "    sagitta = abs(pad_parabola - pad_straight)\n",
    "    \n",
    "    fit_params = {\n",
    "        'pad_params': popt_pad,  # [a, b, c]\n",
    "        'tbin_params': popt_tbin,  # [d, e]\n",
    "        'chi2_pad': chi2_pad,\n",
    "        'chi2_tbin': chi2_tbin,\n",
    "        'sagitta': sagitta,\n",
    "        'n_hits': len(chain),\n",
    "        'total_adc': np.sum(weights)\n",
    "    }\n",
    "    \n",
    "    # Create smooth fit line for drawing\n",
    "    layer_range = np.linspace(layer_min, layer_max, 50)\n",
    "    pad_smooth = parabola(layer_range, *popt_pad)\n",
    "    tbin_smooth = linear(layer_range, *popt_tbin)\n",
    "    \n",
    "    # Create TPolyLine3D for the fit\n",
    "    fit_line = root.TPolyLine3D(len(layer_range))\n",
    "    for i, (t, p, l) in enumerate(zip(tbin_smooth, pad_smooth, layer_range)):\n",
    "        fit_line.SetPoint(i, float(t), float(p), float(l))\n",
    "    \n",
    "    return fit_params, fit_line\n",
    "\n",
    "\n",
    "'''def print_fit_quality(fit_params, chain_type=\"\"):\n",
    "    \"\"\"Print fit quality metrics\"\"\"\n",
    "    if fit_params is None:\n",
    "        print(f\"{chain_type} Fit failed\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{chain_type} Fit Results:\")\n",
    "    print(f\"  Sagitta: {fit_params['sagitta']:.4f}\")\n",
    "    print(f\"  Chi2 (pad): {fit_params['chi2_pad']:.4f}\")\n",
    "    print(f\"  Chi2 (tbin): {fit_params['chi2_tbin']:.4f}\")\n",
    "    print(f\"  N hits: {fit_params['n_hits']}\")\n",
    "    print(f\"  Total ADC: {fit_params['total_adc']:.1f}\")\n",
    "    print(f\"  Pad params [a,b,c]: {fit_params['pad_params']}\")\n",
    "    print(f\"  Tbin params [d,e]: {fit_params['tbin_params']}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_chain_3d(chain_main, key, layers, pts_arr, color, width=2):\n",
    "    \"\"\"\n",
    "    chain_main: list of (layer, j_in_layer) in order\n",
    "    \"\"\"\n",
    "    n = len(chain_main)\n",
    "    if n < 2:\n",
    "        return None\n",
    "\n",
    "    pl = root.TPolyLine3D(n)\n",
    "    pl.SetLineColor(color)\n",
    "    pl.SetLineWidth(width)\n",
    "\n",
    "    for i, (layer, j) in enumerate(chain_main):\n",
    "        gi = layers[layer][\"idx\"][j]  # global index\n",
    "        tbin, pad, layer0 = pts_arr[key][gi]\n",
    "        #print(f\"Chain point {i}: layer={layer0}, tbin={tbin}, pad={pad}\")\n",
    "        pl.SetPoint(i, float(tbin), float(pad), float(layer0))\n",
    "\n",
    "    pl.Draw(\"same\")\n",
    "    return pl\n",
    "\n",
    "CHAIN_COLORS = [\n",
    "    root.kRed + 1,\n",
    "    root.kAzure + 2,\n",
    "    root.kGreen + 2,\n",
    "    root.kMagenta + 1,\n",
    "    root.kOrange + 7,\n",
    "    root.kCyan + 2,\n",
    "    root.kViolet,\n",
    "    root.kPink + 9,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_local_maxima_3d(seeds, key, layers, pts_arr, color, mstyle=20, msize=1.2):\n",
    "    \"\"\"\n",
    "    seeds: list of (layer, j_in_layer)\n",
    "    Draw as TPolyMarker3D at (tbin, pad, layer)\n",
    "    \"\"\"\n",
    "    n = len(seeds)\n",
    "    if n == 0:\n",
    "        return None\n",
    "\n",
    "    pm = root.TPolyMarker3D(n)\n",
    "    pm.SetMarkerColor(color)\n",
    "    pm.SetMarkerStyle(mstyle)\n",
    "    pm.SetMarkerSize(msize)\n",
    "\n",
    "    for i, (layer, j) in enumerate(seeds):\n",
    "        gi = int(layers[layer][\"idx\"][j])  # global index in pts_arr[key]\n",
    "        tbin, pad, layer0 = pts_arr[key][gi]\n",
    "        pm.SetPoint(i, float(tbin), float(pad), float(layer0)+0.5)\n",
    "\n",
    "    pm.Draw(\"same\")   # important: draw on same canvas\n",
    "    return pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def print_final_chains_layer_by_layer(\n",
    "    final_chains, layers,\n",
    "    max_chains=None,\n",
    "    sort_layers=True,\n",
    "    layer_step_hint=None,\n",
    "    layer_min=None,\n",
    "    layer_max=None,\n",
    "):\n",
    "    def _hit_info(layer, j):\n",
    "        ld = layers[int(layer)]\n",
    "        gi = int(ld[\"idx\"][int(j)])\n",
    "        t  = int(ld[\"tp\"][int(j), 0])\n",
    "        p  = int(ld[\"tp\"][int(j), 1])\n",
    "        w  = float(ld[\"adc\"][int(j)])\n",
    "        return gi, t, p, w\n",
    "\n",
    "    n = len(final_chains)\n",
    "    nprint = n if max_chains is None else min(n, int(max_chains))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"FINAL CHAINS: total={n}, printing={nprint}  (layer_min={layer_min}, layer_max={layer_max})\")\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    for ic in range(nprint):\n",
    "        chain_main, chain_support = final_chains[ic]\n",
    "\n",
    "        by_layer = {}\n",
    "        for ly, j in chain_main:\n",
    "            ly = int(ly); j = int(j)\n",
    "            if layer_min is not None and ly < layer_min: continue\n",
    "            if layer_max is not None and ly > layer_max: continue\n",
    "            by_layer.setdefault(ly, {\"main\": [], \"support\": []})[\"main\"].append(j)\n",
    "\n",
    "        for ly, j in chain_support:\n",
    "            ly = int(ly); j = int(j)\n",
    "            if layer_min is not None and ly < layer_min: continue\n",
    "            if layer_max is not None and ly > layer_max: continue\n",
    "            by_layer.setdefault(ly, {\"main\": [], \"support\": []})[\"support\"].append(j)\n",
    "\n",
    "        if not by_layer:\n",
    "            continue  # nothing in requested layer range\n",
    "\n",
    "        layers_list = list(by_layer.keys())\n",
    "        if sort_layers:\n",
    "            if layer_step_hint in (+1, -1):\n",
    "                layers_list.sort(reverse=(layer_step_hint == -1))\n",
    "            else:\n",
    "                layers_list.sort()\n",
    "\n",
    "        n_main = sum(len(by_layer[ly][\"main\"]) for ly in layers_list)\n",
    "        n_sup  = sum(len(by_layer[ly][\"support\"]) for ly in layers_list)\n",
    "\n",
    "        print(\"\\n\" + \"-\"*90)\n",
    "        print(f\"Chain {ic}: n_main={n_main}  n_support={n_sup}  n_layers={len(layers_list)} (filtered)\")\n",
    "        print(\"-\"*90)\n",
    "\n",
    "        for ly in layers_list:\n",
    "            mains = by_layer[ly][\"main\"]\n",
    "            sups  = by_layer[ly][\"support\"]\n",
    "            print(f\"  Layer {ly:3d}: main={len(mains):2d}, support={len(sups):2d}\")\n",
    "\n",
    "            for j in sorted(mains):\n",
    "                gi, t, p, w = _hit_info(ly, j)\n",
    "                print(f\"    M  j={j:4d}  gi={gi:7d}  t={t:5d}  p={p:4d}  adc={w:8.2f}\")\n",
    "\n",
    "            for j in sorted(sups):\n",
    "                gi, t, p, w = _hit_info(ly, j)\n",
    "                print(f\"    S  j={j:4d}  gi={gi:7d}  t={t:5d}  p={p:4d}  adc={w:8.2f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "# Final Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_sector = 0\n",
    "draw_side   = 0\n",
    "\n",
    "canvases = []\n",
    "drawn = {}\n",
    "drawn_chains = {}\n",
    "drawn_fits = {}         # store fit line references (if you re-enable fits)\n",
    "chain_avg_dpdts = {}\n",
    "chain_fit_params = {}   # store fit parameters / histories\n",
    "drawn_seeds  = {}\n",
    "\n",
    "\n",
    "for imod in range(3):\n",
    "    c = root.TCanvas(\n",
    "        f\"c_sec{draw_sector}_s{draw_side}_mod{imod}\",\n",
    "        f\"Sector {draw_sector} Side {draw_side} Module {imod}\",\n",
    "        1500, 1000\n",
    "    )\n",
    "    c.cd()\n",
    "\n",
    "    key = (draw_sector, imod, draw_side)\n",
    "\n",
    "    if key in hists:\n",
    "        h3 = hists[key]\n",
    "        h3.SetTitle(\n",
    "            f\"3D ADC; timebin; pad; layer \"\n",
    "            f\"(sec {draw_sector}, side {draw_side}, mod {imod})\"\n",
    "        )\n",
    "        h3.Draw(\"SCAT\")\n",
    "        drawn[imod] = h3\n",
    "\n",
    "        # ---- build per-key structures ----\n",
    "        layers = build_layer_indices_and_trees(key, pts_arr, payload)\n",
    "\n",
    "        seeds_sorted = find_seeds_sorted(layers)  # (layer, j, adc)\n",
    "        #print(f\"[sec {draw_sector} side {draw_side} mod {imod}] Seeds found:\", len(seeds_sorted))\n",
    "\n",
    "        seeds_for_markers = [(ly, j) for (ly, j, adc) in seeds_sorted]\n",
    "\n",
    "        used_global = set()\n",
    "        seed_set = set((int(ly), int(j)) for (ly, j, adc) in seeds_sorted)\n",
    "\n",
    "        # ---- draw local maxima markers ----\n",
    "        pm = draw_local_maxima_3d(\n",
    "            seeds_for_markers, key, layers, pts_arr,\n",
    "            color=root.kRed + 1,\n",
    "            mstyle=20,\n",
    "            msize=1.6\n",
    "        )\n",
    "        drawn_seeds[imod] = pm\n",
    "\n",
    "        drawn_chains[imod] = []\n",
    "        drawn_fits[imod] = []\n",
    "        chain_fit_params[imod] = {'horizontal': [], 'vertical': []}\n",
    "\n",
    "        # ============================================================\n",
    "        # 1st iteration: HORIZONTAL (same-layer) CHAINS\n",
    "        # ============================================================\n",
    "        horizontal_chains = find_horizontal_chains_allhits(\n",
    "            layers, seeds_sorted, used_global,\n",
    "            dt=2, dp=3,\n",
    "            min_hits=3,\n",
    "            min_pad_span=5,\n",
    "            order_for_drawing=True\n",
    "        )\n",
    "\n",
    "        horizontal_chain_avg_dpdts = []\n",
    "\n",
    "        for ic, chain in enumerate(horizontal_chains):\n",
    "            avg_dp, avg_dt, n_max = chain_avg_dp_dt_between_maxima(chain, layers, seed_set)\n",
    "            horizontal_chain_avg_dpdts.append((avg_dp, avg_dt, n_max))\n",
    "\n",
    "            color = CHAIN_COLORS[ic % len(CHAIN_COLORS)]\n",
    "\n",
    "            # Draw original chain (thin line)\n",
    "            pl = draw_chain_3d(chain, key, layers, pts_arr, color=color, width=2)\n",
    "            if pl:\n",
    "                drawn_chains[imod].append(pl)\n",
    "            \n",
    "\n",
    "            # If you later re-enable horizontal fits, keep it here\n",
    "            # fit_params, fit_line = sagitta_fit_3d(chain, key, layers, pts_arr, payload)\n",
    "            # if fit_line:\n",
    "            #     fit_line.SetLineColor(color); fit_line.SetLineWidth(6); fit_line.SetLineStyle(1)\n",
    "            #     fit_line.Draw(\"same\"); drawn_fits[imod].append(fit_line)\n",
    "            #     chain_fit_params[imod]['horizontal'].append(fit_params)\n",
    "\n",
    "        # ============================================================\n",
    "        # 2nd iteration: VERTICAL chains (TWO PASS)\n",
    "        # ============================================================\n",
    "        vertical_chain_avg_dpdts = []\n",
    "\n",
    "        # Call two_pass_chaining ONCE. Reuse used_global already filled by horizontal pass.\n",
    "        # If your two_pass_chaining signature doesn't yet accept used_global, this try/except\n",
    "        # will fall back (but you really should add used_global support).\n",
    "        seed_set = {(ly, j) for ly, j, adc in seeds_sorted}\n",
    "\n",
    "        final_vertical_chains = two_pass_chaining(\n",
    "            layers, seeds_sorted, seed_set,\n",
    "            dt_win0=3, dp_win0=2,\n",
    "            dt_gate=1, dp_gate=1,\n",
    "            allow_skip_one_layer=True\n",
    "        )\n",
    "        ic = 0\n",
    "        for chain_main, chain_support in final_vertical_chains:\n",
    "            avg_dp, avg_dt, n_max = chain_avg_dp_dt_between_maxima(\n",
    "                chain_main, layers, seed_set\n",
    "            )\n",
    "            \n",
    "           \n",
    "        \n",
    "            '''print(\"=\"*68)\n",
    "            print(f\"LEN len(chain_main) {len(chain_main)}\")\n",
    "            print(\"=\"*68)'''\n",
    "            if len(chain_main) < 3:\n",
    "                continue\n",
    "            color = CHAIN_COLORS[ic % len(CHAIN_COLORS)]\n",
    "            '''fit_params, fit_line = sagitta_fit_3d(chain_main, key, layers, pts_arr, payload)\n",
    "            if fit_line:\n",
    "                fit_line.SetLineColor(color)\n",
    "                fit_line.SetLineWidth(6)\n",
    "                fit_line.SetLineStyle(1)  # dashed line for fit\n",
    "                fit_line.Draw(\"same\")\n",
    "                drawn_fits[imod].append(fit_line)\n",
    "                chain_fit_params[imod]['vertical'].append(fit_params)\n",
    "                \n",
    "                # Print fit quality for first few chains\n",
    "                if ic < 3:\n",
    "                    print(f\"\\nVertical Chain {ic} (module {imod}):\")\n",
    "                    print_fit_quality(fit_params, f\"  \")'''\n",
    "\n",
    "\n",
    "\n",
    "            # Draw vertical chain (thicker line)\n",
    "            pl = draw_chain_3d(chain_main, key, layers, pts_arr, color=color, width=4)\n",
    "            if pl:\n",
    "                drawn_chains[imod].append(pl)\n",
    "            ic += 1\n",
    "\n",
    "            \n",
    "\n",
    "           \n",
    "\n",
    "            # If you want to dump/inspect:\n",
    "            # dump_chain(key, chain_main, [], layers, pts_arr, payload)\n",
    "\n",
    "            # If you later re-enable vertical fits, keep it here\n",
    "            # fit_params, fit_line = sagitta_fit_3d(\n",
    "            #     chain_main, key, layers, pts_arr, payload,\n",
    "            #     use_perigee_for_vertical=False\n",
    "            # )\n",
    "            # chain_fit_params[imod]['vertical'].append({\"imod\": imod, \"fit\": fit_params})\n",
    "            # if fit_line:\n",
    "            #     fit_line.SetLineColor(color); fit_line.SetLineWidth(6); fit_line.SetLineStyle(1)\n",
    "            #     fit_line.Draw(\"same\"); drawn_fits[imod].append(fit_line)\n",
    "\n",
    "        chain_avg_dpdts[imod] = {\n",
    "            \"horizontal\": horizontal_chain_avg_dpdts,\n",
    "            \"vertical\": vertical_chain_avg_dpdts,\n",
    "        }\n",
    "\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(f\"[sec {draw_sector} side {draw_side} mod {imod}] Vertical chains found:\", len(final_vertical_chains))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    c.Update()\n",
    "    canvases.append(c)\n",
    "\n",
    "for c in canvases:\n",
    "    c.Draw()\n",
    "\n",
    "# Print summary statistics\n",
    "'''print(\"\\n\" + \"=\"*60)\n",
    "print(\"=\"*60)\n",
    "for imod in range(3):\n",
    "    if imod in chain_fit_params:\n",
    "        h_fits = chain_fit_params[imod]['horizontal']\n",
    "        v_fits = chain_fit_params[imod]['vertical']\n",
    "\n",
    "        print(f\"\\nModule {imod}:\")\n",
    "        print(f\"  Horizontal chains (fits stored): {len(h_fits)}\")\n",
    "        print(f\"  Vertical chains (fits stored):   {len(v_fits)}\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_bin_width = [0.0053073, 0.00530732, 0.00530731]\n",
    "module_radius = [\n",
    "    [29.854978828112735, 31.869737083177956, 32.43665978627038, 33.00171100689825, 33.56863172731403, 34.133682357783, 34.70060474122243, 35.26565540941076, 35.83257683544541, 36.39762877363545, 36.964549975549694, 37.52960055896088, 38.09652180558749, 38.66157293473739, 39.228495272708216, 39.793545257944906],\n",
    "    [41.65920253621078, 42.67990048015332, 43.7005755287188, 44.7212729094545, 45.7419615067264, 46.76264656230158, 47.78333428983602, 48.80401878201343, 49.82471910526506, 50.8454060012135, 51.866093793785126, 52.88677964073831, 53.90746625152035, 54.92815969895385, 55.948864895868056, 56.9695394315422],\n",
    "    [58.910963349324035, 60.00800996331871, 61.10505851260341, 62.202104676954924, 63.29915863086735, 64.39619682986867, 65.49324606923312, 66.59029899562653, 67.68734047670296, 68.78439383353172, 69.88143340055497, 70.97848786511186, 72.07553264226554, 73.17257662017182, 74.2696338511705, 75.36667517343196],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store all chain hits with classifications and draw in phi-radius-timebin coordinates\n",
    "# All sectors and modules combined per side\n",
    "\n",
    "import ROOT as root\n",
    "import numpy as np\n",
    "\n",
    "# Storage for all chain hits\n",
    "all_chain_hits = {}  # {(sector, side, imod): [chain_data]}\n",
    "\n",
    "# Process ALL sectors and modules\n",
    "for sector in range(24):  # All 24 sectors\n",
    "    for imod in range(3):\n",
    "        for side in [0, 1]:\n",
    "            key = (sector, imod, side)\n",
    "            \n",
    "            if key not in hists:\n",
    "                continue\n",
    "            \n",
    "            # Rebuild layers for this module\n",
    "            layers = build_layer_indices_and_trees(key, pts_arr, payload)\n",
    "            seeds_sorted = find_seeds_sorted(layers)\n",
    "            seed_set = {(ly, j) for ly, j, adc in seeds_sorted}\n",
    "            used_global = set()\n",
    "            \n",
    "            # Find horizontal chains\n",
    "            horizontal_chains = find_horizontal_chains_allhits(\n",
    "                layers, seeds_sorted, used_global,\n",
    "                dt=2, dp=3, min_hits=3, min_pad_span=5, order_for_drawing=True\n",
    "            )\n",
    "            \n",
    "            # Find vertical chains (two-pass)\n",
    "            final_vertical_chains = two_pass_chaining(\n",
    "                layers, seeds_sorted, seed_set,\n",
    "                dt_win0=3, dp_win0=2, dt_gate=1, dp_gate=1,\n",
    "                allow_skip_one_layer=True\n",
    "            )\n",
    "            \n",
    "            # Store data for this module\n",
    "            all_chain_hits[key] = []\n",
    "            \n",
    "            # Process horizontal chains\n",
    "            for ic, chain in enumerate(horizontal_chains):\n",
    "                chain_data = {\n",
    "                    'chain_id': f'S{sector}_M{imod}_H{ic}',\n",
    "                    'chain_type': 'horizontal',\n",
    "                    'sector': sector,\n",
    "                    'module': imod,\n",
    "                    'side': side,\n",
    "                    'hits': []\n",
    "                }\n",
    "                \n",
    "                for layer_num, j in chain:\n",
    "                    ld = layers.get(int(layer_num))\n",
    "                    if ld is None:\n",
    "                        continue\n",
    "                    \n",
    "                    t = int(ld[\"tp\"][j, 0])\n",
    "                    p = int(ld[\"tp\"][j, 1])\n",
    "                    adc = float(ld[\"adc\"][j])\n",
    "                    \n",
    "                    # Convert to phi-radius coordinates\n",
    "                    # Add sector offset to phi\n",
    "                    phi_local = p * phi_bin_width[imod]\n",
    "                    phi_global = phi_local + sector * (2 * np.pi / 24)\n",
    "                    radius = module_radius[imod][(layer_num - 7) % 16]\n",
    "                    \n",
    "                    is_main = (int(layer_num), int(j)) in seed_set\n",
    "                    \n",
    "                    chain_data['hits'].append({\n",
    "                        'layer': layer_num,\n",
    "                        'timebin': t,\n",
    "                        'pad': p,\n",
    "                        'phi': phi_global,\n",
    "                        'radius': radius,\n",
    "                        'adc': adc,\n",
    "                        'hit_type': 'main' if is_main else 'support'\n",
    "                    })\n",
    "                \n",
    "                all_chain_hits[key].append(chain_data)\n",
    "            \n",
    "            # Process vertical chains\n",
    "            for ic, (chain_main, chain_support) in enumerate(final_vertical_chains):\n",
    "                if len(chain_main) < 3:\n",
    "                    continue\n",
    "                    \n",
    "                chain_data = {\n",
    "                    'chain_id': f'S{sector}_M{imod}_V{ic}',\n",
    "                    'chain_type': 'vertical',\n",
    "                    'sector': sector,\n",
    "                    'module': imod,\n",
    "                    'side': side,\n",
    "                    'hits': []\n",
    "                }\n",
    "                \n",
    "                # Process main hits\n",
    "                for layer_num, j in chain_main:\n",
    "                    ld = layers.get(int(layer_num))\n",
    "                    if ld is None:\n",
    "                        continue\n",
    "                    \n",
    "                    t = int(ld[\"tp\"][j, 0])\n",
    "                    p = int(ld[\"tp\"][j, 1])\n",
    "                    adc = float(ld[\"adc\"][j])\n",
    "                    \n",
    "                    phi_local = p * phi_bin_width[imod]\n",
    "                    phi_global = phi_local + sector * (2 * np.pi / 24)\n",
    "                    radius = module_radius[imod][(layer_num - 7) % 16]\n",
    "                    \n",
    "                    chain_data['hits'].append({\n",
    "                        'layer': layer_num,\n",
    "                        'timebin': t,\n",
    "                        'pad': p,\n",
    "                        'phi': phi_global,\n",
    "                        'radius': radius,\n",
    "                        'adc': adc,\n",
    "                        'hit_type': 'main'\n",
    "                    })\n",
    "                \n",
    "                # Process support hits\n",
    "                for layer_num, j in chain_support:\n",
    "                    ld = layers.get(int(layer_num))\n",
    "                    if ld is None:\n",
    "                        continue\n",
    "                    \n",
    "                    t = int(ld[\"tp\"][j, 0])\n",
    "                    p = int(ld[\"tp\"][j, 1])\n",
    "                    adc = float(ld[\"adc\"][j])\n",
    "                    \n",
    "                    phi_local = p * phi_bin_width[imod]\n",
    "                    phi_global = phi_local + sector * (2 * np.pi / 24)\n",
    "                    radius = module_radius[imod][(layer_num - 7) % 16]\n",
    "                    \n",
    "                    chain_data['hits'].append({\n",
    "                        'layer': layer_num,\n",
    "                        'timebin': t,\n",
    "                        'pad': p,\n",
    "                        'phi': phi_global,\n",
    "                        'radius': radius,\n",
    "                        'adc': adc,\n",
    "                        'hit_type': 'support'\n",
    "                    })\n",
    "                \n",
    "                all_chain_hits[key].append(chain_data)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHAIN HITS STORAGE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "total_chains = 0\n",
    "for key, chains in all_chain_hits.items():\n",
    "    sector, imod, side = key\n",
    "    total_chains += len(chains)\n",
    "\n",
    "print(f\"Total chains stored: {total_chains}\")\n",
    "for side in [0, 1]:\n",
    "    side_chains = sum(len(chains) for key, chains in all_chain_hits.items() if key[2] == side)\n",
    "    print(f\"  Side {side}: {side_chains} chains\")\n",
    "\n",
    "# Create visualizations - ONE canvas per side with ALL sectors and modules combined\n",
    "vis_canvases = []\n",
    "\n",
    "for side in [0, 1]:\n",
    "    c = root.TCanvas(\n",
    "        f\"c_phi_radius_side{side}_all\",\n",
    "        f\"Phi-Radius-Timebin View - Side {side} (All Sectors & Modules)\",\n",
    "        1600, 1200\n",
    "    )\n",
    "    c.cd()\n",
    "    \n",
    "    # Create 3D histogram for this side (all data combined)\n",
    "    h_phi_r_t = root.TH3F(\n",
    "        f\"h_phi_r_t_side{side}_all\",\n",
    "        f\"Side {side} - All Sectors & Modules; #phi (rad); radius (cm); timebin\",\n",
    "        150, 0, 2*np.pi,  # Full phi range (0 to 2π)\n",
    "        150, 28, 78,      # Full radius range (covers all 3 modules)\n",
    "        150, 0, 500       # timebin range\n",
    "    )\n",
    "    \n",
    "    # Collect all hits for this side\n",
    "    \n",
    "    chain_counter = 0\n",
    "    \n",
    "    for sector in range(24):\n",
    "        for imod in range(3):\n",
    "            key = (sector, imod, side)\n",
    "            \n",
    "            if key not in all_chain_hits:\n",
    "                continue\n",
    "            \n",
    "            chains = all_chain_hits[key]\n",
    "            \n",
    "            # Draw each chain\n",
    "            for chain in chains:\n",
    "                color = CHAIN_COLORS[chain_counter % len(CHAIN_COLORS)]\n",
    "                \n",
    "                # Separate main and support hits\n",
    "                main_hits = [h for h in chain['hits'] if h['hit_type'] == 'main']\n",
    "                support_hits = [h for h in chain['hits'] if h['hit_type'] == 'support']\n",
    "                \n",
    "                # Draw main hits (larger markers)\n",
    "                if main_hits:\n",
    "                    graph_main = root.TGraph2D(len(main_hits))\n",
    "                    for i, hit in enumerate(main_hits):\n",
    "                        graph_main.SetPoint(i, hit['phi'], hit['radius'], hit['timebin'])\n",
    "                        h_phi_r_t.Fill(hit['phi'], hit['radius'], hit['timebin'], hit['adc'])\n",
    "                    \n",
    "                    graph_main.SetMarkerColor(color)\n",
    "                    graph_main.SetMarkerStyle(20)\n",
    "                    graph_main.SetMarkerSize(0.8)\n",
    "                    if chain_counter == 0:\n",
    "                        graph_main.Draw(\"P\")\n",
    "                    else:\n",
    "                        graph_main.Draw(\"P SAME\")\n",
    "                \n",
    "                # Draw support hits (smaller markers)\n",
    "                if support_hits:\n",
    "                    graph_support = root.TGraph2D(len(support_hits))\n",
    "                    for i, hit in enumerate(support_hits):\n",
    "                        graph_support.SetPoint(i, hit['phi'], hit['radius'], hit['timebin'])\n",
    "                        h_phi_r_t.Fill(hit['phi'], hit['radius'], hit['timebin'], hit['adc'])\n",
    "                    \n",
    "                    graph_support.SetMarkerColor(color)\n",
    "                    graph_support.SetMarkerStyle(24)  # open circle\n",
    "                    graph_support.SetMarkerSize(0.5)\n",
    "                    graph_support.Draw(\"P SAME\")\n",
    "                \n",
    "                chain_counter += 1\n",
    "    \n",
    "    # Draw the 3D histogram\n",
    "    h_phi_r_t.SetMarkerStyle(20)\n",
    "    h_phi_r_t.SetMarkerSize(0.3)\n",
    "    h_phi_r_t.Draw(\"SCAT\")\n",
    "    \n",
    "    '''graph_all_hits = root.TGraph2D(len(cluster_points_cyl))\n",
    "    for i in range(len(cluster_points_cyl)):\n",
    "        graph_all_hits.SetPoint(i, \n",
    "                                cluster_points_cyl[i, 1], \n",
    "                                cluster_points_cyl[i, 0], \n",
    "                                cluster_points_cyl[i, 2])\n",
    "        \n",
    "    #graph_all_hits.SetMarkerStyle(7)  # small dots\n",
    "    graph_all_hits.SetMarkerColor(root.kRed)\n",
    "    graph_all_hits.Draw(\"P SAME\")'''\n",
    "    \n",
    "    c.Update()\n",
    "    vis_canvases.append(c)\n",
    "\n",
    "# Draw all canvases\n",
    "for c in vis_canvases:\n",
    "    c.Draw()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VISUALIZATION COMPLETE\")\n",
    "print(f\"Created {len(vis_canvases)} canvases (one per side)\")\n",
    "print(\"Each canvas shows ALL sectors and modules combined\")\n",
    "print(\"Main hits: filled circles (larger)\")\n",
    "print(\"Support hits: open circles (smaller)\")\n",
    "print(\"Phi range: 0 to 2π (full azimuthal coverage)\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "# Plot parameter space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "#import seaborn as sns\n",
    "\n",
    "class TrackFitClusterer:\n",
    "    \"\"\"\n",
    "    Cluster track fits based on their parameters in 5D space.\n",
    "    Finds groups of tracks with similar fit parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fit_data = []\n",
    "        self.scaler = StandardScaler()\n",
    "        self.labels = None\n",
    "        self.normalized_params = None\n",
    "        \n",
    "    def add_fit(self, fit_params, metadata=None):\n",
    "        \"\"\"\n",
    "        Add a fit result from sagitta_fit_3d to the collection.\n",
    "        \n",
    "        Args:\n",
    "            fit_params: dict returned from sagitta_fit_3d\n",
    "            metadata: optional dict with additional info (e.g., event_id, track_id)\n",
    "        \"\"\"\n",
    "        if fit_params is None:\n",
    "            return\n",
    "            \n",
    "        fit_entry = {\n",
    "            'pad_a': fit_params['pad_params'][0],\n",
    "            'pad_b': fit_params['pad_params'][1],\n",
    "            'pad_c': fit_params['pad_params'][2],\n",
    "            'tbin_d': fit_params['tbin_params'][0],\n",
    "            'tbin_e': fit_params['tbin_params'][1],\n",
    "            'chi2_pad': fit_params['chi2_pad'],\n",
    "            'chi2_tbin': fit_params['chi2_tbin'],\n",
    "            'sagitta': fit_params['sagitta'],\n",
    "            'n_hits': fit_params['n_hits'],\n",
    "            'total_adc': fit_params['total_adc'],\n",
    "        }\n",
    "        \n",
    "        if metadata:\n",
    "            fit_entry.update(metadata)\n",
    "            \n",
    "        self.fit_data.append(fit_entry)\n",
    "        \n",
    "    def cluster(self, eps=0.5, min_samples=2, weights=None):\n",
    "        \"\"\"\n",
    "        Perform clustering on collected fits.\n",
    "        \n",
    "        Args:\n",
    "            eps: DBSCAN epsilon parameter (distance threshold in normalized space)\n",
    "            min_samples: minimum number of points to form a cluster\n",
    "            weights: dict to weight parameters differently, e.g., {'pad_a': 2.0, 'tbin_d': 1.0}\n",
    "        \n",
    "        Returns:\n",
    "            labels: cluster assignments (-1 for noise)\n",
    "        \"\"\"\n",
    "        if len(self.fit_data) < 2:\n",
    "            print(\"Need at least 2 fits for clustering\")\n",
    "            return None\n",
    "            \n",
    "        # Extract parameters for clustering\n",
    "        param_names = ['pad_a', 'pad_b', 'pad_c', 'tbin_d', 'tbin_e']\n",
    "        X = np.array([[fit[p] for p in param_names] for fit in self.fit_data])\n",
    "        \n",
    "        # Normalize parameters\n",
    "        self.normalized_params = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Apply weights if provided\n",
    "        if weights:\n",
    "            for i, param in enumerate(param_names):\n",
    "                if param in weights:\n",
    "                    self.normalized_params[:, i] *= weights[param]\n",
    "        \n",
    "        # Cluster using DBSCAN\n",
    "        clusterer = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        self.labels = clusterer.fit_predict(self.normalized_params)\n",
    "        \n",
    "        # Add cluster labels to fit_data\n",
    "        for i, fit in enumerate(self.fit_data):\n",
    "            fit['cluster'] = self.labels[i]\n",
    "        \n",
    "        return self.labels\n",
    "    \n",
    "    def get_cluster_stats(self):\n",
    "        \"\"\"Get statistics for each cluster\"\"\"\n",
    "        if self.labels is None:\n",
    "            print(\"Run cluster() first\")\n",
    "            return None\n",
    "            \n",
    "        unique_labels = set(self.labels)\n",
    "        unique_labels.discard(-1)  # Remove noise label\n",
    "        \n",
    "        stats = {}\n",
    "        for label in unique_labels:\n",
    "            cluster_fits = [f for f in self.fit_data if f['cluster'] == label]\n",
    "            \n",
    "            stats[label] = {\n",
    "                'n_fits': len(cluster_fits),\n",
    "                'avg_sagitta': np.mean([f['sagitta'] for f in cluster_fits]),\n",
    "                'std_sagitta': np.std([f['sagitta'] for f in cluster_fits]),\n",
    "                'avg_chi2_pad': np.mean([f['chi2_pad'] for f in cluster_fits]),\n",
    "                'avg_chi2_tbin': np.mean([f['chi2_tbin'] for f in cluster_fits]),\n",
    "                'avg_n_hits': np.mean([f['n_hits'] for f in cluster_fits]),\n",
    "                'avg_total_adc': np.mean([f['total_adc'] for f in cluster_fits]),\n",
    "                'avg_params': {\n",
    "                    'pad_a': np.mean([f['pad_a'] for f in cluster_fits]),\n",
    "                    'pad_b': np.mean([f['pad_b'] for f in cluster_fits]),\n",
    "                    'pad_c': np.mean([f['pad_c'] for f in cluster_fits]),\n",
    "                    'tbin_d': np.mean([f['tbin_d'] for f in cluster_fits]),\n",
    "                    'tbin_e': np.mean([f['tbin_e'] for f in cluster_fits]),\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Add noise stats\n",
    "        noise_fits = [f for f in self.fit_data if f['cluster'] == -1]\n",
    "        if noise_fits:\n",
    "            stats[-1] = {\n",
    "                'n_fits': len(noise_fits),\n",
    "                'avg_sagitta': np.mean([f['sagitta'] for f in noise_fits]),\n",
    "            }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def plot_clusters(self, view='pad_a_vs_b', figsize=(15, 10)):\n",
    "        \"\"\"\n",
    "        Visualize clusters in parameter space.\n",
    "        \n",
    "        Args:\n",
    "            view: which parameters to plot\n",
    "                'pad_a_vs_b', 'tbin_d_vs_e', 'sagitta_vs_chi2', \n",
    "                'pad_params', 'all'\n",
    "        \"\"\"\n",
    "        if self.labels is None:\n",
    "            print(\"Run cluster() first\")\n",
    "            return\n",
    "        \n",
    "        views = {\n",
    "            'pad_a_vs_b': ('pad_a', 'pad_b', 'Pad Curvature (a)', 'Pad Slope (b)'),\n",
    "            'tbin_d_vs_e': ('tbin_d', 'tbin_e', 'Tbin Slope (d)', 'Tbin Intercept (e)'),\n",
    "            'sagitta_vs_chi2': ('sagitta', 'chi2_pad', 'Sagitta', 'Chi² (pad)'),\n",
    "            'pad_params': ('pad_b', 'pad_c', 'Pad Slope (b)', 'Pad Intercept (c)'),\n",
    "        }\n",
    "        \n",
    "        if view == 'all':\n",
    "            fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "            axes = axes.flatten()\n",
    "            \n",
    "            for idx, (view_name, (x_key, y_key, x_label, y_label)) in enumerate(views.items()):\n",
    "                self._plot_single_view(axes[idx], x_key, y_key, x_label, y_label)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "        else:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "            x_key, y_key, x_label, y_label = views[view]\n",
    "            self._plot_single_view(ax, x_key, y_key, x_label, y_label)\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_single_view(self, ax, x_key, y_key, x_label, y_label):\n",
    "        \"\"\"Helper to plot a single view\"\"\"\n",
    "        x = [f[x_key] for f in self.fit_data]\n",
    "        y = [f[y_key] for f in self.fit_data]\n",
    "        \n",
    "        unique_labels = set(self.labels)\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "        \n",
    "        for label, color in zip(unique_labels, colors):\n",
    "            if label == -1:\n",
    "                # Noise points\n",
    "                mask = self.labels == label\n",
    "                ax.scatter(np.array(x)[mask], np.array(y)[mask], \n",
    "                          c='gray', marker='x', s=50, alpha=0.3, label='Noise')\n",
    "            else:\n",
    "                mask = self.labels == label\n",
    "                ax.scatter(np.array(x)[mask], np.array(y)[mask],\n",
    "                          c=[color], marker='o', s=100, alpha=0.7, \n",
    "                          label=f'Cluster {label}', edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        ax.set_xlabel(x_label, fontsize=11)\n",
    "        ax.set_ylabel(y_label, fontsize=11)\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def plot_distance_matrix(self):\n",
    "        \"\"\"Plot pairwise distance matrix in normalized parameter space\"\"\"\n",
    "        if self.normalized_params is None:\n",
    "            print(\"Run cluster() first\")\n",
    "            return\n",
    "        \n",
    "        # Compute pairwise distances\n",
    "        distances = squareform(pdist(self.normalized_params, metric='euclidean'))\n",
    "        \n",
    "        # Sort by cluster label for better visualization\n",
    "        sorted_indices = np.argsort(self.labels)\n",
    "        distances_sorted = distances[sorted_indices][:, sorted_indices]\n",
    "        labels_sorted = self.labels[sorted_indices]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        im = ax.imshow(distances_sorted, cmap='viridis', aspect='auto')\n",
    "        \n",
    "        # Add cluster boundaries\n",
    "        cluster_changes = np.where(np.diff(labels_sorted) != 0)[0] + 0.5\n",
    "        for change in cluster_changes:\n",
    "            ax.axhline(change, color='red', linewidth=2)\n",
    "            ax.axvline(change, color='red', linewidth=2)\n",
    "        \n",
    "        plt.colorbar(im, ax=ax, label='Normalized Distance')\n",
    "        ax.set_xlabel('Fit Index (sorted by cluster)', fontsize=11)\n",
    "        ax.set_ylabel('Fit Index (sorted by cluster)', fontsize=11)\n",
    "        ax.set_title('Pairwise Distance Matrix', fontsize=13, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print summary of clustering results\"\"\"\n",
    "        if self.labels is None:\n",
    "            print(\"Run cluster() first\")\n",
    "            return\n",
    "        \n",
    "        stats = self.get_cluster_stats()\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"TRACK FIT CLUSTERING SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Total fits: {len(self.fit_data)}\")\n",
    "        print(f\"Number of clusters: {len([l for l in set(self.labels) if l != -1])}\")\n",
    "        print(f\"Noise points: {np.sum(self.labels == -1)}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for label in sorted(stats.keys()):\n",
    "            if label == -1:\n",
    "                print(f\"\\nNoise Points: {stats[label]['n_fits']} fits\")\n",
    "                print(f\"  Avg Sagitta: {stats[label]['avg_sagitta']:.4f}\")\n",
    "            else:\n",
    "                print(f\"\\nCluster {label}: {stats[label]['n_fits']} fits\")\n",
    "                print(f\"  Sagitta: {stats[label]['avg_sagitta']:.4f} ± {stats[label]['std_sagitta']:.4f}\")\n",
    "                print(f\"  Chi² (pad): {stats[label]['avg_chi2_pad']:.4f}\")\n",
    "                print(f\"  Chi² (tbin): {stats[label]['avg_chi2_tbin']:.4f}\")\n",
    "                print(f\"  Avg hits: {stats[label]['avg_n_hits']:.1f}\")\n",
    "                print(f\"  Avg ADC: {stats[label]['avg_total_adc']:.1f}\")\n",
    "                print(f\"  Avg Params:\")\n",
    "                print(f\"    Pad: a={stats[label]['avg_params']['pad_a']:.5f}, \"\n",
    "                      f\"b={stats[label]['avg_params']['pad_b']:.3f}, \"\n",
    "                      f\"c={stats[label]['avg_params']['pad_c']:.2f}\")\n",
    "                print(f\"    Tbin: d={stats[label]['avg_params']['tbin_d']:.3f}, \"\n",
    "                      f\"e={stats[label]['avg_params']['tbin_e']:.2f}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize clusterer\n",
    "clusterer = TrackFitClusterer()\n",
    "\n",
    "# Example: Process your fits from the sagitta_fit_3d function\n",
    "# Assuming you have chains of hits and you run sagitta_fit_3d on each chain:\n",
    "\n",
    "\"\"\"\n",
    "for chain_id, chain in enumerate(your_chains):\n",
    "    fit_params, fit_line = sagitta_fit_3d(chain, key, layers, pts_arr, payload)\n",
    "    \n",
    "    if fit_params is not None:\n",
    "        # Add fit to clusterer with metadata\n",
    "        clusterer.add_fit(fit_params, metadata={\n",
    "            'chain_id': chain_id,\n",
    "            'event_id': event_id  # if you have event information\n",
    "        })\n",
    "\"\"\"\n",
    "\n",
    "# For demonstration, let's create some synthetic fits\n",
    "print(\"Generating synthetic fit data for demonstration...\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate 3 types of tracks with different characteristics\n",
    "track_types = [\n",
    "    {'pad_a': 0.01, 'pad_b': 0.5, 'pad_c': 10, 'tbin_d': 2.0, 'tbin_e': 5},\n",
    "    {'pad_a': -0.02, 'pad_b': -0.3, 'pad_c': 15, 'tbin_d': 1.5, 'tbin_e': 8},\n",
    "    {'pad_a': 0.005, 'pad_b': 0.8, 'pad_c': 12, 'tbin_d': 2.5, 'tbin_e': 3},\n",
    "]\n",
    "\n",
    "for i in range(100):\n",
    "    track_type = track_types[i % 3]\n",
    "    noise = 0.3\n",
    "    \n",
    "    synthetic_fit = {\n",
    "        'pad_params': [\n",
    "            track_type['pad_a'] + np.random.randn() * 0.003,\n",
    "            track_type['pad_b'] + np.random.randn() * 0.15,\n",
    "            track_type['pad_c'] + np.random.randn() * 1.0,\n",
    "        ],\n",
    "        'tbin_params': [\n",
    "            track_type['tbin_d'] + np.random.randn() * 0.15,\n",
    "            track_type['tbin_e'] + np.random.randn() * 0.8,\n",
    "        ],\n",
    "        'chi2_pad': np.abs(np.random.randn() * 0.5 + 0.5),\n",
    "        'chi2_tbin': np.abs(np.random.randn() * 0.5 + 0.5),\n",
    "        'sagitta': np.abs(track_type['pad_a']) * 10 + np.abs(np.random.randn() * 0.3),\n",
    "        'n_hits': int(np.random.randint(5, 15)),\n",
    "        'total_adc': np.random.rand() * 500 + 500,\n",
    "    }\n",
    "    \n",
    "    clusterer.add_fit(synthetic_fit, metadata={'track_id': i})\n",
    "\n",
    "print(f\"Added {len(clusterer.fit_data)} fits\")\n",
    "\n",
    "# Perform clustering\n",
    "print(\"\\nRunning clustering algorithm...\")\n",
    "labels = clusterer.cluster(eps=0.5, min_samples=3)\n",
    "\n",
    "# Print summary\n",
    "clusterer.print_summary()\n",
    "\n",
    "# Visualize results\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "clusterer.plot_clusters(view='all')\n",
    "clusterer.plot_distance_matrix()\n",
    "\n",
    "# Get cluster statistics for further analysis\n",
    "stats = clusterer.get_cluster_stats()\n",
    "\n",
    "# Example: Find all fits in a specific cluster\n",
    "cluster_0_fits = [f for f in clusterer.fit_data if f['cluster'] == 0]\n",
    "print(f\"\\nCluster 0 contains {len(cluster_0_fits)} fits\")\n",
    "print(f\"Track IDs in Cluster 0: {[f['track_id'] for f in cluster_0_fits[:10]]}...\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def print_final_chains_layer_by_layer(\n",
    "    final_chains, layers,\n",
    "    max_chains=None,\n",
    "    sort_layers=True,\n",
    "    layer_step_hint=None,\n",
    "    layer_min=None,\n",
    "    layer_max=None,\n",
    "):\n",
    "    def _hit_info(layer, j):\n",
    "        ld = layers[int(layer)]\n",
    "        gi = int(ld[\"idx\"][int(j)])\n",
    "        t  = int(ld[\"tp\"][int(j), 0])\n",
    "        p  = int(ld[\"tp\"][int(j), 1])\n",
    "        w  = float(ld[\"adc\"][int(j)])\n",
    "        return gi, t, p, w\n",
    "\n",
    "    n = len(final_chains)\n",
    "    nprint = n if max_chains is None else min(n, int(max_chains))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"FINAL CHAINS: total={n}, printing={nprint}  (layer_min={layer_min}, layer_max={layer_max})\")\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    for ic in range(nprint):\n",
    "        chain_main, chain_support = final_chains[ic]\n",
    "\n",
    "        by_layer = {}\n",
    "        for ly, j in chain_main:\n",
    "            ly = int(ly); j = int(j)\n",
    "            if layer_min is not None and ly < layer_min: continue\n",
    "            if layer_max is not None and ly > layer_max: continue\n",
    "            by_layer.setdefault(ly, {\"main\": [], \"support\": []})[\"main\"].append(j)\n",
    "\n",
    "        for ly, j in chain_support:\n",
    "            ly = int(ly); j = int(j)\n",
    "            if layer_min is not None and ly < layer_min: continue\n",
    "            if layer_max is not None and ly > layer_max: continue\n",
    "            by_layer.setdefault(ly, {\"main\": [], \"support\": []})[\"support\"].append(j)\n",
    "\n",
    "        if not by_layer:\n",
    "            continue  # nothing in requested layer range\n",
    "\n",
    "        layers_list = list(by_layer.keys())\n",
    "        if sort_layers:\n",
    "            if layer_step_hint in (+1, -1):\n",
    "                layers_list.sort(reverse=(layer_step_hint == -1))\n",
    "            else:\n",
    "                layers_list.sort()\n",
    "\n",
    "        n_main = sum(len(by_layer[ly][\"main\"]) for ly in layers_list)\n",
    "        n_sup  = sum(len(by_layer[ly][\"support\"]) for ly in layers_list)\n",
    "\n",
    "        print(\"\\n\" + \"-\"*90)\n",
    "        print(f\"Chain {ic}: n_main={n_main}  n_support={n_sup}  n_layers={len(layers_list)} (filtered)\")\n",
    "        print(\"-\"*90)\n",
    "\n",
    "        for ly in layers_list:\n",
    "            mains = by_layer[ly][\"main\"]\n",
    "            sups  = by_layer[ly][\"support\"]\n",
    "            print(f\"  Layer {ly:3d}: main={len(mains):2d}, support={len(sups):2d}\")\n",
    "\n",
    "            for j in sorted(mains):\n",
    "                gi, t, p, w = _hit_info(ly, j)\n",
    "                print(f\"    M  j={j:4d}  gi={gi:7d}  t={t:5d}  p={p:4d}  adc={w:8.2f}\")\n",
    "\n",
    "            for j in sorted(sups):\n",
    "                gi, t, p, w = _hit_info(ly, j)\n",
    "                print(f\"    S  j={j:4d}  gi={gi:7d}  t={t:5d}  p={p:4d}  adc={w:8.2f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print_final_chains_layer_by_layer(\n",
    "    final_vertical_chains, layers,\n",
    "    layer_max=22,          # <-- only layers <= 22\n",
    "    layer_step_hint=+1\n",
    ")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# ============================================================\n",
    "# SAVE ALL CHAINS (horizontal + vertical) FOR ALL\n",
    "# sectors 0-11, sides 0-1, modules (from available keys)\n",
    "# into ONE ROOT file that you can read from another notebook.\n",
    "# ============================================================\n",
    "\n",
    "import ROOT as root\n",
    "from array import array\n",
    "\n",
    "out_root = \"/Users/mitrankova/Jupyter/PatternRecognition/all_chains.root\"\n",
    "\n",
    "# --- open output ROOT ---\n",
    "fout = root.TFile.Open(out_root, \"RECREATE\")\n",
    "if not fout or fout.IsZombie():\n",
    "    raise RuntimeError(f\"Cannot create {out_root}\")\n",
    "\n",
    "# -------------------------\n",
    "# Flat per-hit tree (robust)\n",
    "# -------------------------\n",
    "th = root.TTree(\"ChainHits\", \"One entry per hit with chain metadata\")\n",
    "\n",
    "# scalars (arrays)\n",
    "sec_a       = array('i', [0])\n",
    "side_a      = array('i', [0])\n",
    "mod_a       = array('i', [0])\n",
    "chain_uid_a = array('i', [0])   # unique across whole file\n",
    "chain_id_a  = array('i', [0])   # local id within (sec,side,mod,chain_type)\n",
    "chain_type_a= array('i', [0])   # 0=horizontal, 1=vertical\n",
    "is_main_a   = array('i', [0])   # 1=main, 0=support\n",
    "\n",
    "layer_a     = array('i', [0])\n",
    "j_a         = array('i', [0])\n",
    "gi_a        = array('i', [0])\n",
    "t_a         = array('i', [0])\n",
    "p_a         = array('i', [0])\n",
    "adc_a       = array('f', [0.0])\n",
    "\n",
    "th.Branch(\"sec\",       sec_a,        \"sec/I\")\n",
    "th.Branch(\"side\",      side_a,       \"side/I\")\n",
    "th.Branch(\"mod\",       mod_a,        \"mod/I\")\n",
    "th.Branch(\"chain_uid\", chain_uid_a,  \"chain_uid/I\")\n",
    "th.Branch(\"chain_id\",  chain_id_a,   \"chain_id/I\")\n",
    "th.Branch(\"chain_type\",chain_type_a, \"chain_type/I\")\n",
    "th.Branch(\"is_main\",   is_main_a,    \"is_main/I\")\n",
    "\n",
    "th.Branch(\"layer\",     layer_a,      \"layer/I\")\n",
    "th.Branch(\"j\",         j_a,          \"j/I\")\n",
    "th.Branch(\"gi\",        gi_a,         \"gi/I\")\n",
    "th.Branch(\"t\",         t_a,          \"t/I\")\n",
    "th.Branch(\"p\",         p_a,          \"p/I\")\n",
    "th.Branch(\"adc\",       adc_a,        \"adc/F\")\n",
    "\n",
    "# -------------------------\n",
    "# Optional per-chain summary\n",
    "# -------------------------\n",
    "tc = root.TTree(\"Chains\", \"One entry per chain summary\")\n",
    "sec2_a       = array('i', [0])\n",
    "side2_a      = array('i', [0])\n",
    "mod2_a       = array('i', [0])\n",
    "chain_uid2_a = array('i', [0])\n",
    "chain_id2_a  = array('i', [0])\n",
    "chain_type2_a= array('i', [0])\n",
    "n_main_a     = array('i', [0])\n",
    "n_sup_a      = array('i', [0])\n",
    "n_layers_a   = array('i', [0])\n",
    "\n",
    "tc.Branch(\"sec\",       sec2_a,       \"sec/I\")\n",
    "tc.Branch(\"side\",      side2_a,      \"side/I\")\n",
    "tc.Branch(\"mod\",       mod2_a,       \"mod/I\")\n",
    "tc.Branch(\"chain_uid\", chain_uid2_a, \"chain_uid/I\")\n",
    "tc.Branch(\"chain_id\",  chain_id2_a,  \"chain_id/I\")\n",
    "tc.Branch(\"chain_type\",chain_type2_a,\"chain_type/I\")\n",
    "tc.Branch(\"n_main\",    n_main_a,     \"n_main/I\")\n",
    "tc.Branch(\"n_support\", n_sup_a,      \"n_support/I\")\n",
    "tc.Branch(\"n_layers\",  n_layers_a,   \"n_layers/I\")\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def _hit_fields(layers, ly, j):\n",
    "    ld = layers[int(ly)]\n",
    "    gi = int(ld[\"idx\"][int(j)])\n",
    "    tt = int(ld[\"tp\"][int(j), 0])\n",
    "    pp = int(ld[\"tp\"][int(j), 1])\n",
    "    ww = float(ld[\"adc\"][int(j)])\n",
    "    return gi, tt, pp, ww\n",
    "\n",
    "def _fill_chain_hits(sec, side, mod, chain_uid, chain_id_local, chain_type,\n",
    "                     chain_main, chain_support, layers):\n",
    "    # per-chain summary\n",
    "    sec2_a[0]        = int(sec)\n",
    "    side2_a[0]       = int(side)\n",
    "    mod2_a[0]        = int(mod)\n",
    "    chain_uid2_a[0]  = int(chain_uid)\n",
    "    chain_id2_a[0]   = int(chain_id_local)\n",
    "    chain_type2_a[0] = int(chain_type)\n",
    "    n_main_a[0]      = int(len(chain_main))\n",
    "    n_sup_a[0]       = int(len(chain_support))\n",
    "\n",
    "    # unique layers count across main+support\n",
    "    layset = set(int(ly) for (ly, _) in chain_main)\n",
    "    layset.update(int(ly) for (ly, _) in chain_support)\n",
    "    n_layers_a[0] = int(len(layset))\n",
    "    tc.Fill()\n",
    "\n",
    "    # per-hit rows: MAIN\n",
    "    for ly, j in chain_main:\n",
    "        gi, tt, pp, ww = _hit_fields(layers, ly, j)\n",
    "        sec_a[0]        = int(sec)\n",
    "        side_a[0]       = int(side)\n",
    "        mod_a[0]        = int(mod)\n",
    "        chain_uid_a[0]  = int(chain_uid)\n",
    "        chain_id_a[0]   = int(chain_id_local)\n",
    "        chain_type_a[0] = int(chain_type)\n",
    "        is_main_a[0]    = 1\n",
    "\n",
    "        layer_a[0] = int(ly)\n",
    "        j_a[0]     = int(j)\n",
    "        gi_a[0]    = int(gi)\n",
    "        t_a[0]     = int(tt)\n",
    "        p_a[0]     = int(pp)\n",
    "        adc_a[0]   = float(ww)\n",
    "        th.Fill()\n",
    "\n",
    "    # per-hit rows: SUPPORT\n",
    "    for ly, j in chain_support:\n",
    "        gi, tt, pp, ww = _hit_fields(layers, ly, j)\n",
    "        sec_a[0]        = int(sec)\n",
    "        side_a[0]       = int(side)\n",
    "        mod_a[0]        = int(mod)\n",
    "        chain_uid_a[0]  = int(chain_uid)\n",
    "        chain_id_a[0]   = int(chain_id_local)\n",
    "        chain_type_a[0] = int(chain_type)\n",
    "        is_main_a[0]    = 0\n",
    "\n",
    "        layer_a[0] = int(ly)\n",
    "        j_a[0]     = int(j)\n",
    "        gi_a[0]    = int(gi)\n",
    "        t_a[0]     = int(tt)\n",
    "        p_a[0]     = int(pp)\n",
    "        adc_a[0]   = float(ww)\n",
    "        th.Fill()\n",
    "\n",
    "# -------------------------\n",
    "# Main loop over all keys\n",
    "# -------------------------\n",
    "chain_uid = 0\n",
    "n_keys = 0\n",
    "n_chains_total = 0\n",
    "\n",
    "# determine module range from hists keys if available\n",
    "# expected key: (sec, imod, side)\n",
    "mods_in_hists = sorted({int(k[1]) for k in hists.keys()}) if \"hists\" in globals() else [0,1,2]\n",
    "\n",
    "for sec in range(12):\n",
    "    for side in (0, 1):\n",
    "        for imod in mods_in_hists:\n",
    "            key = (sec, imod, side)\n",
    "            if key not in hists:\n",
    "                continue\n",
    "\n",
    "            n_keys += 1\n",
    "\n",
    "            # Build per-key layer structures\n",
    "            layers = build_layer_indices_and_trees(key, pts_arr, payload)\n",
    "\n",
    "            # Seeds\n",
    "            seeds_sorted = find_seeds_sorted(layers)  # (layer, j, adc)\n",
    "            seed_set = set((int(ly), int(j)) for (ly, j, adc) in seeds_sorted)\n",
    "\n",
    "            # used within THIS (sec,side,mod) only\n",
    "            used_global = set()\n",
    "\n",
    "            # -------------------------\n",
    "            # HORIZONTAL chains\n",
    "            # -------------------------\n",
    "            horizontal_chains = find_horizontal_chains_allhits(\n",
    "                layers, seeds_sorted, used_global,\n",
    "                dt=2, dp=3,\n",
    "                min_hits=3,\n",
    "                min_pad_span=5,\n",
    "                order_for_drawing=True\n",
    "            )\n",
    "\n",
    "            # store horizontal: treat as \"main only\", no support\n",
    "            chain_id_local = 0\n",
    "            for ch in horizontal_chains:\n",
    "                if len(ch) < 2:\n",
    "                    continue\n",
    "                _fill_chain_hits(\n",
    "                    sec, side, imod,\n",
    "                    chain_uid=chain_uid,\n",
    "                    chain_id_local=chain_id_local,\n",
    "                    chain_type=0,                # 0=horizontal\n",
    "                    chain_main=ch,\n",
    "                    chain_support=[],\n",
    "                    layers=layers\n",
    "                )\n",
    "                chain_uid += 1\n",
    "                chain_id_local += 1\n",
    "                n_chains_total += 1\n",
    "\n",
    "            # -------------------------\n",
    "            # VERTICAL chains (two pass)\n",
    "            # -------------------------\n",
    "            final_vertical_chains = two_pass_chaining(\n",
    "                layers, seeds_sorted, seed_set,\n",
    "                dt_win0=3, dp_win0=2,\n",
    "                dt_gate=1, dp_gate=1,\n",
    "                allow_skip_one_layer=True\n",
    "                # If you upgraded your two_pass_chaining to accept used_global, pass it here:\n",
    "                # , used_global=used_global\n",
    "            )\n",
    "\n",
    "            chain_id_local = 0\n",
    "            for (chain_main, chain_support) in final_vertical_chains:\n",
    "                if len(chain_main) < 2:\n",
    "                    continue\n",
    "                _fill_chain_hits(\n",
    "                    sec, side, imod,\n",
    "                    chain_uid=chain_uid,\n",
    "                    chain_id_local=chain_id_local,\n",
    "                    chain_type=1,                # 1=vertical\n",
    "                    chain_main=chain_main,\n",
    "                    chain_support=chain_support,\n",
    "                    layers=layers\n",
    "                )\n",
    "                chain_uid += 1\n",
    "                chain_id_local += 1\n",
    "                n_chains_total += 1\n",
    "\n",
    "            if (n_keys % 10) == 0:\n",
    "                print(f\"[progress] keys processed={n_keys}, chains stored={n_chains_total}\")\n",
    "\n",
    "# write and close\n",
    "fout.cd()\n",
    "tc.Write()\n",
    "th.Write()\n",
    "fout.Close()\n",
    "\n",
    "print(\"============================================================\")\n",
    "print(f\"Saved to: {out_root}\")\n",
    "print(f\"Keys processed: {n_keys}\")\n",
    "print(f\"Chains stored:  {n_chains_total}\")\n",
    "#print(f\"Total hits rows in ChainHits: {th.GetEntries()}\")\n",
    "print(\"============================================================\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
